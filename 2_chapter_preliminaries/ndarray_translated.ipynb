{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0de623d7",
   "metadata": {
    "origin_pos": 1
   },
   "source": [
    "# 数据操作\n",
    ":label:`sec_ndarray`\n",
    "\n",
    "为了完成任何事情，\n",
    "我们需要某种方式来存储和处理数据。\n",
    "通常，我们需要对数据做两件重要的事情：\n",
    "（i）获取数据；\n",
    "（ii）在数据进入计算机后对其进行处理。\n",
    "如果没有办法存储数据，获取数据是没有意义的，\n",
    "因此，让我们从$n$-维数组开始动手，\n",
    "我们也称之为*张量*。\n",
    "如果你已经熟悉了NumPy科学计算包，\n",
    "这将非常简单。\n",
    "对于所有现代深度学习框架，\n",
    "*张量类*（MXNet中的`ndarray`，\n",
    "PyTorch和TensorFlow中的`Tensor`）\n",
    "类似于NumPy的`ndarray`，\n",
    "并增加了一些关键特性。\n",
    "首先，张量类支持自动微分。\n",
    "其次，它利用GPU加速数值计算，\n",
    "而NumPy只能在CPU上运行。\n",
    "这些特性使得神经网络\n",
    "既易于编码又运行快速。\n",
    "\n",
    "\n",
    "\n",
    "## 开始\n",
    "\n",
    "\n",
    "请提供翻译结果，无需任何额外解释，并移除。如果翻译是不必要的（例如专有名词、代码等），返回原文。无解释。无注释。确保输出格式与输入格式完全相同。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084dc517",
   "metadata": {
    "origin_pos": 3,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "(**首先，我们导入PyTorch库。\n",
    "请注意，包名是`torch`。**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "01fa8e58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T19:32:55.152236Z",
     "iopub.status.busy": "2023-08-18T19:32:55.151500Z",
     "iopub.status.idle": "2023-08-18T19:32:57.051589Z",
     "shell.execute_reply": "2023-08-18T19:32:57.050409Z"
    },
    "origin_pos": 6,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d828de8",
   "metadata": {
    "origin_pos": 9
   },
   "source": [
    "[**张量表示数值的（可能是多维的）数组。**]\n",
    "在一维情况下，即数据只需要一个轴时，\n",
    "张量被称为*向量*。\n",
    "在有两个轴的情况下，张量被称为*矩阵*。\n",
    "当有 $k > 2$ 个轴时，我们不再使用专门的名称，\n",
    "而只是将该对象称为 $k^\\textrm{th}$-*阶张量*。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a471639",
   "metadata": {
    "origin_pos": 11,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "PyTorch 提供了多种函数来创建预填充值的新张量。例如，通过调用 `arange(n)`，我们可以创建一个均匀分布的值的向量，从 0（包括）开始到 `n`（不包括）。默认情况下，间隔大小为 $1$。除非另有说明，新张量存储在主内存中，并指定用于基于 CPU 的计算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "b6aa30a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T19:32:57.056039Z",
     "iopub.status.busy": "2023-08-18T19:32:57.055276Z",
     "iopub.status.idle": "2023-08-18T19:32:57.089028Z",
     "shell.execute_reply": "2023-08-18T19:32:57.088195Z"
    },
    "origin_pos": 14,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.])"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(12, dtype=torch.float32)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a12b5d8",
   "metadata": {
    "origin_pos": 18,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "这些值中的每一个都被称为张量的*元素*。\n",
    "张量`x`包含12个元素。\n",
    "我们可以通过张量的`numel`方法检查张量中元素的总数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "640cadaf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T19:32:57.093138Z",
     "iopub.status.busy": "2023-08-18T19:32:57.092473Z",
     "iopub.status.idle": "2023-08-18T19:32:57.098450Z",
     "shell.execute_reply": "2023-08-18T19:32:57.097452Z"
    },
    "origin_pos": 21,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.numel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50c7483",
   "metadata": {
    "origin_pos": 23
   },
   "source": [
    "（**我们可以访问张量的*形状***）\n",
    "（每个轴的长度）\n",
    "通过检查其`shape`属性。\n",
    "因为这里处理的是一个向量，\n",
    "`shape`只包含一个元素\n",
    "并且与大小相同。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "6e0a9616",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T19:32:57.102194Z",
     "iopub.status.busy": "2023-08-18T19:32:57.101575Z",
     "iopub.status.idle": "2023-08-18T19:32:57.107424Z",
     "shell.execute_reply": "2023-08-18T19:32:57.106501Z"
    },
    "origin_pos": 24,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12])"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c60413a",
   "metadata": {
    "origin_pos": 25
   },
   "source": [
    "我们可以通过调用`reshape`来[**改变张量的形状而不改变其大小或值**]。例如，我们可以将形状为(12,)的向量`x`转换为形状为(3, 4)的矩阵`X`。这个新的张量保留了所有元素，但将它们重新配置成一个矩阵。请注意，我们的向量中的元素是按行依次排列的，因此`x[3] == X[0, 3]`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "6092207c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T19:32:57.111467Z",
     "iopub.status.busy": "2023-08-18T19:32:57.110749Z",
     "iopub.status.idle": "2023-08-18T19:32:57.117759Z",
     "shell.execute_reply": "2023-08-18T19:32:57.116917Z"
    },
    "origin_pos": 26,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.,  3.],\n",
       "        [ 4.,  5.,  6.,  7.],\n",
       "        [ 8.,  9., 10., 11.]])"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = x.reshape(3, 4)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2e1706",
   "metadata": {
    "origin_pos": 28
   },
   "source": [
    "请注意，为`reshape`指定每个形状组件是多余的。因为我们已经知道张量的大小，所以可以根据其余部分推断出形状的一个组件。例如，给定一个大小为$n$的张量和目标形状（$h$，$w$），我们知道$w = n/h$。为了自动推断形状的一个组件，我们可以将应该自动推断的形状组件设置为`-1`。在我们的情况下，除了调用`x.reshape(3, 4)`之外，还可以等效地调用`x.reshape(-1, 4)`或`x.reshape(3, -1)`。\n",
    "\n",
    "实践者经常需要处理初始化为全0或全1的张量。[**我们可以通过`zeros`函数构造一个所有元素都设置为0**] (~~或1~~)且形状为(2, 3, 4)的张量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "383cafca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T19:32:57.122018Z",
     "iopub.status.busy": "2023-08-18T19:32:57.121194Z",
     "iopub.status.idle": "2023-08-18T19:32:57.128294Z",
     "shell.execute_reply": "2023-08-18T19:32:57.127285Z"
    },
    "origin_pos": 30,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros((2, 3, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e967d02",
   "metadata": {
    "origin_pos": 33
   },
   "source": [
    "同样，我们可以通过调用`ones`来创建一个全为1的张量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "0ea249d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T19:32:57.132534Z",
     "iopub.status.busy": "2023-08-18T19:32:57.131716Z",
     "iopub.status.idle": "2023-08-18T19:32:57.139029Z",
     "shell.execute_reply": "2023-08-18T19:32:57.138135Z"
    },
    "origin_pos": 35,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones((2, 3, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0615f2d6",
   "metadata": {
    "origin_pos": 38
   },
   "source": [
    "我们经常希望从给定的概率分布中随机（且独立地）抽取每个元素。例如，神经网络的参数通常会被随机初始化。以下代码片段创建了一个张量，其元素是从均值为0、标准差为1的标准高斯（正态）分布中抽取的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "2254595d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T19:32:57.143051Z",
     "iopub.status.busy": "2023-08-18T19:32:57.142388Z",
     "iopub.status.idle": "2023-08-18T19:32:57.149695Z",
     "shell.execute_reply": "2023-08-18T19:32:57.148813Z"
    },
    "origin_pos": 40,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3620,  0.0494,  0.5405, -0.3573],\n",
       "        [-0.0776, -0.9660, -0.2192,  1.0989],\n",
       "        [-0.4543, -0.2755,  1.5128, -2.6399]])"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(3, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35eda39",
   "metadata": {
    "origin_pos": 43
   },
   "source": [
    "最后，我们可以通过\n",
    "[**为每个元素提供确切的值**]\n",
    "通过提供（可能是嵌套的）包含数值字面量的Python列表来构建张量。\n",
    "这里，我们使用一个列表的列表来构造一个矩阵，\n",
    "其中最外层的列表对应于轴0，\n",
    "内层列表对应于轴1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "b26863d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T19:32:57.153567Z",
     "iopub.status.busy": "2023-08-18T19:32:57.153222Z",
     "iopub.status.idle": "2023-08-18T19:32:57.160436Z",
     "shell.execute_reply": "2023-08-18T19:32:57.159548Z"
    },
    "origin_pos": 45,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 1, 4, 3],\n",
       "        [1, 2, 3, 4],\n",
       "        [4, 3, 2, 1]])"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[2, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b589cdb",
   "metadata": {
    "origin_pos": 48
   },
   "source": [
    "## 索引和切片\n",
    "\n",
    "与 Python 列表一样，\n",
    "我们可以通过索引（从0开始）访问张量元素。\n",
    "要根据列表末尾的位置访问元素，\n",
    "我们可以使用负索引。\n",
    "最后，我们可以通过切片（例如，`X[start:stop]`）访问整个范围的索引，\n",
    "返回的值包括第一个索引（`start`）*但不包括最后一个*（`stop`）。\n",
    "最后，当只为一个 $k^\\textrm{th}$ 阶张量指定一个索引（或切片）时，\n",
    "它将应用于轴0。\n",
    "因此，在以下代码中，\n",
    "[**`[-1]` 选择最后一行，而 `[1:3]` 选择第二和第三行**]。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "d9049a53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T19:32:57.164537Z",
     "iopub.status.busy": "2023-08-18T19:32:57.163812Z",
     "iopub.status.idle": "2023-08-18T19:32:57.171699Z",
     "shell.execute_reply": "2023-08-18T19:32:57.170451Z"
    },
    "origin_pos": 49,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 8.,  9., 10., 11.]),\n",
       " tensor([[ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.]]))"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[-1], X[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5450673b",
   "metadata": {
    "origin_pos": 50,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "除了阅读它们，（**我们还可以通过指定索引来*写入*矩阵的元素。**）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "9246619c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T19:32:57.176047Z",
     "iopub.status.busy": "2023-08-18T19:32:57.175685Z",
     "iopub.status.idle": "2023-08-18T19:32:57.182893Z",
     "shell.execute_reply": "2023-08-18T19:32:57.181890Z"
    },
    "origin_pos": 52,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.,  3.],\n",
       "        [ 4.,  5., 17.,  7.],\n",
       "        [ 8.,  9., 10., 11.]])"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1, 2] = 17\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f06903",
   "metadata": {
    "origin_pos": 55
   },
   "source": [
    "如果我们要[**为多个元素分配相同的值，\n",
    "我们在赋值操作的左侧应用索引。**]\n",
    "例如，`[:2, :]` 访问\n",
    "第一和第二行，\n",
    "其中 `:` 沿轴1（列）取所有元素。\n",
    "虽然我们讨论了矩阵的索引，\n",
    "但这同样适用于向量\n",
    "以及超过二维的张量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "0532f024",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T19:32:57.186970Z",
     "iopub.status.busy": "2023-08-18T19:32:57.186270Z",
     "iopub.status.idle": "2023-08-18T19:32:57.193303Z",
     "shell.execute_reply": "2023-08-18T19:32:57.192338Z"
    },
    "origin_pos": 56,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[12., 12., 12., 12.],\n",
       "        [12., 12., 12., 12.],\n",
       "        [ 8.,  9., 10., 11.]])"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:2, :] = 12\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cdce97",
   "metadata": {
    "origin_pos": 59
   },
   "source": [
    "## 操作\n",
    "\n",
    "现在我们已经知道如何构造张量\n",
    "以及如何读取和写入它们的元素，\n",
    "我们可以开始使用各种数学操作来处理它们。\n",
    "其中最有用的是*逐元素*操作。\n",
    "这些操作将标准的标量操作\n",
    "应用于张量的每个元素。\n",
    "对于接受两个张量作为输入的函数，\n",
    "逐元素操作会对每对对应的元素应用某种标准的二元运算符。\n",
    "我们可以从任何将标量映射到标量的函数\n",
    "创建一个逐元素函数。\n",
    "\n",
    "在数学符号中，我们将这样的\n",
    "*一元*标量运算符（接受一个输入）\n",
    "表示为签名\n",
    "$f: \\mathbb{R} \\rightarrow \\mathbb{R}$。\n",
    "这仅仅意味着该函数将\n",
    "任何实数映射到另一个实数。\n",
    "大多数标准运算符，包括像 $e^x$ 这样的单目运算符，都可以逐元素应用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "6dd6724c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T19:32:57.197301Z",
     "iopub.status.busy": "2023-08-18T19:32:57.196599Z",
     "iopub.status.idle": "2023-08-18T19:32:57.206136Z",
     "shell.execute_reply": "2023-08-18T19:32:57.205188Z"
    },
    "origin_pos": 61,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([162754.7969, 162754.7969, 162754.7969, 162754.7969, 162754.7969,\n",
       "        162754.7969, 162754.7969, 162754.7969,   2980.9580,   8103.0840,\n",
       "         22026.4648,  59874.1406])"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70f353f",
   "metadata": {
    "origin_pos": 64
   },
   "source": [
    "同样，我们表示*二元*标量运算符，\n",
    "这些运算符将实数对\n",
    "映射到一个（单一的）实数\n",
    "通过签名\n",
    "$f: \\mathbb{R}, \\mathbb{R} \\rightarrow \\mathbb{R}$。\n",
    "给定任意两个*形状相同*的向量$\\mathbf{u}$\n",
    "和$\\mathbf{v}$，以及一个二元运算符$f$，我们可以通过设置$c_i \\gets f(u_i, v_i)$对于所有的$i$来生成一个向量$\\mathbf{c} = F(\\mathbf{u},\\mathbf{v})$，\n",
    "其中$c_i, u_i$和$v_i$分别是向量$\\mathbf{c}, \\mathbf{u}$和$\\mathbf{v}$的第$i$个元素。\n",
    "这里，我们通过*提升*标量函数\n",
    "为逐元素向量操作产生了向量值的\n",
    "$F: \\mathbb{R}^d, \\mathbb{R}^d \\rightarrow \\mathbb{R}^d$。\n",
    "常见的标准算术运算符\n",
    "加法 (`+`)、减法 (`-`)、\n",
    "乘法 (`*`)、除法 (`/`)、\n",
    "和幂运算 (`**`)\n",
    "都已经被*提升*为任意形状的同形张量的逐元素操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "89bc996d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T19:32:57.210417Z",
     "iopub.status.busy": "2023-08-18T19:32:57.209741Z",
     "iopub.status.idle": "2023-08-18T19:32:57.219298Z",
     "shell.execute_reply": "2023-08-18T19:32:57.218318Z"
    },
    "origin_pos": 66,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 3.,  4.,  6., 10.]),\n",
       " tensor([-1.,  0.,  2.,  6.]),\n",
       " tensor([ 2.,  4.,  8., 16.]),\n",
       " tensor([0.5000, 1.0000, 2.0000, 4.0000]),\n",
       " tensor([ 1.,  4., 16., 64.]))"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1.0, 2, 4, 8])\n",
    "y = torch.tensor([2, 2, 2, 2])\n",
    "x + y, x - y, x * y, x / y, x ** y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ae1d38",
   "metadata": {
    "origin_pos": 69
   },
   "source": [
    "除了逐元素计算之外，我们还可以执行线性代数运算，例如点积和矩阵乘法。我们将在:numref:`sec_linear-algebra`中详细讨论这些内容。\n",
    "\n",
    "我们还可以将多个张量**连接**起来，将它们端对端堆叠以形成一个更大的张量。我们只需要提供一个张量列表，并告诉系统沿着哪个轴进行连接。下面的例子展示了当我们沿着行（轴0）而不是列（轴1）连接两个矩阵时会发生什么。我们可以看到，第一个输出的轴0长度（$6$）是两个输入张量的轴0长度之和（$3 + 3$）；而第二个输出的轴1长度（$8$）是两个输入张量的轴1长度之和（$4 + 4$）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "43aa9012",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T19:32:57.223534Z",
     "iopub.status.busy": "2023-08-18T19:32:57.222711Z",
     "iopub.status.idle": "2023-08-18T19:32:57.233166Z",
     "shell.execute_reply": "2023-08-18T19:32:57.232145Z"
    },
    "origin_pos": 71,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.],\n",
       "         [ 2.,  1.,  4.,  3.],\n",
       "         [ 1.,  2.,  3.,  4.],\n",
       "         [ 4.,  3.,  2.,  1.]]),\n",
       " tensor([[ 0.,  1.,  2.,  3.,  2.,  1.,  4.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.,  1.,  2.,  3.,  4.],\n",
       "         [ 8.,  9., 10., 11.,  4.,  3.,  2.,  1.]]))"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(12, dtype=torch.float32).reshape((3,4))\n",
    "Y = torch.tensor([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])\n",
    "torch.cat((X, Y), dim=0), torch.cat((X, Y), dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346adeed",
   "metadata": {
    "origin_pos": 74
   },
   "source": [
    "有时，我们想要\n",
    "[**通过*逻辑语句*构建一个二进制张量。**]\n",
    "以 `X == Y` 为例。\n",
    "对于每个位置 `i, j`，如果 `X[i, j]` 和 `Y[i, j]` 相等，\n",
    "则结果中的相应条目取值 `1`，\n",
    "否则取值 `0`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "91d39e58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T19:32:57.237276Z",
     "iopub.status.busy": "2023-08-18T19:32:57.236485Z",
     "iopub.status.idle": "2023-08-18T19:32:57.243133Z",
     "shell.execute_reply": "2023-08-18T19:32:57.242117Z"
    },
    "origin_pos": 75,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True, False,  True],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False]])"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X == Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00448db5",
   "metadata": {
    "origin_pos": 76
   },
   "source": [
    "[**对张量中的所有元素求和**]会得到一个只有一个元素的张量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "080b0125",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T19:32:57.247142Z",
     "iopub.status.busy": "2023-08-18T19:32:57.246480Z",
     "iopub.status.idle": "2023-08-18T19:32:57.253117Z",
     "shell.execute_reply": "2023-08-18T19:32:57.252212Z"
    },
    "origin_pos": 77,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(66.)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a78360",
   "metadata": {
    "origin_pos": 79
   },
   "source": [
    "## 广播\n",
    ":label:`subsec_broadcasting`\n",
    "\n",
    "到目前为止，你已经知道如何对两个形状相同的张量执行逐元素二元操作。在某些条件下，即使形状不同，我们仍然可以通过调用*广播机制*来执行逐元素二元操作。广播的工作原理如下两步程序：(i) 通过沿长度为1的轴复制元素来扩展一个或两个数组，使得经过这种变换后，两个张量具有相同的形状；(ii) 对生成的数组执行逐元素操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "be37d2de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T19:32:57.256932Z",
     "iopub.status.busy": "2023-08-18T19:32:57.256264Z",
     "iopub.status.idle": "2023-08-18T19:32:57.263823Z",
     "shell.execute_reply": "2023-08-18T19:32:57.262881Z"
    },
    "origin_pos": 81,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0],\n",
       "         [1],\n",
       "         [2]]),\n",
       " tensor([[0, 1]]))"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(3).reshape((3, 1))\n",
    "b = torch.arange(2).reshape((1, 2))\n",
    "a, b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7e8410",
   "metadata": {
    "origin_pos": 84
   },
   "source": [
    "由于`a`和`b`分别是$3\\times1$和$1\\times2$矩阵，它们的形状不匹配。广播机制通过沿列复制矩阵`a`和沿行复制矩阵`b`来生成一个更大的$3\\times2$矩阵，然后逐元素相加。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "9f62e827",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T19:32:57.267856Z",
     "iopub.status.busy": "2023-08-18T19:32:57.267172Z",
     "iopub.status.idle": "2023-08-18T19:32:57.273497Z",
     "shell.execute_reply": "2023-08-18T19:32:57.272587Z"
    },
    "origin_pos": 85,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [1, 2],\n",
       "        [2, 3]])"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d68609",
   "metadata": {
    "origin_pos": 86
   },
   "source": [
    "## 保存内存\n",
    "\n",
    "[**运行操作可能会导致分配新的内存以存储结果。**]\n",
    "例如，如果我们写 `Y = X + Y`，\n",
    "我们取消了 `Y` 原来指向的张量的引用，\n",
    "而是让 `Y` 指向新分配的内存。\n",
    "我们可以用 Python 的 `id()` 函数来演示这个问题，\n",
    "该函数可以给出内存中引用对象的确切地址。\n",
    "请注意，在我们运行 `Y = Y + X` 之后，\n",
    "`id(Y)` 指向了一个不同的位置。\n",
    "这是因为 Python 首先计算 `Y + X`，\n",
    "为结果分配新的内存，\n",
    "然后让 `Y` 指向这个新的内存位置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "754a7433",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T19:32:57.277697Z",
     "iopub.status.busy": "2023-08-18T19:32:57.277047Z",
     "iopub.status.idle": "2023-08-18T19:32:57.283549Z",
     "shell.execute_reply": "2023-08-18T19:32:57.282613Z"
    },
    "origin_pos": 87,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before = id(Y)\n",
    "Y = Y + X\n",
    "id(Y) == before"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322d26f5",
   "metadata": {
    "origin_pos": 88
   },
   "source": [
    "这可能有两个原因不理想。\n",
    "首先，我们不想一直\n",
    "无谓地分配内存。\n",
    "在机器学习中，我们经常有\n",
    "数百兆字节的参数\n",
    "并且每秒更新多次。\n",
    "只要有可能，我们希望*就地*执行这些更新。\n",
    "其次，我们可能会从多个变量指向\n",
    "相同的参数。\n",
    "如果我们不就地更新，\n",
    "我们必须小心更新所有这些引用，\n",
    "以免出现内存泄漏\n",
    "或无意中引用了过时的参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82880947",
   "metadata": {
    "origin_pos": 89,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "幸运的是，（执行就地操作）很简单。我们可以通过使用切片表示法 `Y[:] = <表达式>` 将操作的结果赋值给预先分配的数组 `Y`。为了说明这个概念，我们在初始化张量 `Z` 后覆盖其值，使用 `zeros_like` 使其与 `Y` 具有相同的形状。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "c4d62609",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T19:32:57.287695Z",
     "iopub.status.busy": "2023-08-18T19:32:57.286964Z",
     "iopub.status.idle": "2023-08-18T19:32:57.293078Z",
     "shell.execute_reply": "2023-08-18T19:32:57.292048Z"
    },
    "origin_pos": 92,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id(Z): 140558549083504\n",
      "id(Z): 140558549083504\n"
     ]
    }
   ],
   "source": [
    "Z = torch.zeros_like(Y)\n",
    "print('id(Z):', id(Z))\n",
    "Z[:] = X + Y\n",
    "print('id(Z):', id(Z))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d745b125",
   "metadata": {
    "origin_pos": 95,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "[**如果`X`的值在后续计算中不再使用，我们也可以使用`X[:] = X + Y`或`X += Y`来减少操作的内存开销。**]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "b8c13447",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T19:32:57.296911Z",
     "iopub.status.busy": "2023-08-18T19:32:57.296361Z",
     "iopub.status.idle": "2023-08-18T19:32:57.302754Z",
     "shell.execute_reply": "2023-08-18T19:32:57.301805Z"
    },
    "origin_pos": 97,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before = id(X)\n",
    "X += Y\n",
    "id(X) == before"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f887dd",
   "metadata": {
    "origin_pos": 99
   },
   "source": [
    "## 转换为其他 Python 对象"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd057d04",
   "metadata": {
    "origin_pos": 101,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "[**转换为NumPy张量 (`ndarray`)**]，或者反过来，都是很容易的。\n",
    "torch张量和NumPy数组\n",
    "将共享它们底层的内存，\n",
    "并且通过就地操作更改其中一个\n",
    "也会更改另一个。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "576963aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T19:32:57.306812Z",
     "iopub.status.busy": "2023-08-18T19:32:57.306088Z",
     "iopub.status.idle": "2023-08-18T19:32:57.312356Z",
     "shell.execute_reply": "2023-08-18T19:32:57.311478Z"
    },
    "origin_pos": 103,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, torch.Tensor)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = X.numpy()\n",
    "B = torch.from_numpy(A)\n",
    "type(A), type(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2def017",
   "metadata": {
    "origin_pos": 106
   },
   "source": [
    "要（将大小为1的张量转换为Python标量），我们可以调用`item`函数或Python的内置函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "388c5252",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T19:32:57.316471Z",
     "iopub.status.busy": "2023-08-18T19:32:57.315825Z",
     "iopub.status.idle": "2023-08-18T19:32:57.322867Z",
     "shell.execute_reply": "2023-08-18T19:32:57.322007Z"
    },
    "origin_pos": 108,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3.5000]), 3.5, 3.5, 3)"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([3.5])\n",
    "a, a.item(), float(a), int(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9373077d",
   "metadata": {
    "origin_pos": 111
   },
   "source": [
    "## 摘要\n",
    "\n",
    "张量类是深度学习库中存储和操作数据的主要接口。\n",
    "张量提供了多种功能，包括构造例程；索引和切片；基本数学运算；广播；内存高效的赋值；以及与其他Python对象之间的转换。\n",
    "\n",
    "## 练习\n",
    "\n",
    "1. 运行本节中的代码。将条件语句 `X == Y` 更改为 `X < Y` 或 `X > Y`，然后看看能得到什么样的张量。\n",
    "1. 将广播机制中按元素操作的两个张量替换为其他形状，例如3维张量。结果是否符合预期？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2776415",
   "metadata": {
    "origin_pos": 113,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "[讨论](https://discuss.d2l.ai/t/27)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l-en",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "required_libs": []
 },
 "nbformat": 4,
 "nbformat_minor": 5
}