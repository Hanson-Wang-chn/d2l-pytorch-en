{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7660a4c",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# 附录：深度学习的数学\n",
    ":label:`chap_appendix_math`\n",
    "\n",
    "**Brent Werness** (*Amazon*), **Rachel Hu** (*Amazon*), 和本书作者\n",
    "\n",
    "\n",
    "现代深度学习的美好之处在于，无需完全理解其下的数学知识即可理解和使用大部分内容。这是一个该领域正在成熟的标志。就像大多数软件开发人员不再需要担心可计算函数的理论一样，深度学习从业者也不需要担心最大似然学习的理论基础。\n",
    "\n",
    "但是，我们还没有完全达到这一点。\n",
    "\n",
    "实际上，有时你需要了解架构选择如何影响梯度流动，或者通过特定损失函数训练时所做的隐含假设。你可能需要知道熵到底测量的是什么，以及它如何帮助你准确理解模型中的每字符比特数。这些都需要更深入的数学理解。\n",
    "\n",
    "本附录旨在为你提供理解现代深度学习核心理论所需的数学背景，但它并不是详尽无遗的。我们将从更深入地研究线性代数开始。我们将对所有常见的线性代数对象和操作发展出几何理解，这将使我们能够可视化各种变换对我们数据的影响。一个关键要素是基本特征分解的发展。\n",
    "\n",
    "接下来，我们将微分学理论发展到足以充分理解为什么梯度是下降最快的方向，以及为什么反向传播采用这种形式的程度。然后讨论积分学，以支持我们的下一个话题——概率论。\n",
    "\n",
    "实践中遇到的问题往往是不确定的，因此我们需要一种语言来谈论不确定的事物。我们回顾随机变量理论和最常遇到的分布，以便我们可以用概率方式讨论模型。这为朴素贝叶斯分类器这一概率分类技术提供了基础。\n",
    "\n",
    "与概率论密切相关的是统计学的研究。虽然统计学是一个太大的领域，在短短一节中无法全面介绍，但我们将介绍所有机器学习实践者都应该了解的基本概念，特别是：评估和比较估计量、进行假设检验以及构建置信区间。\n",
    "\n",
    "最后，我们转向信息论的话题，即关于信息存储和传输的数学研究。这为我们提供了可以定量讨论模型在话语域上包含多少信息的核心语言。\n",
    "\n",
    "综上所述，这些构成了开始深入理解深度学习所需的核心数学概念。\n",
    "\n",
    ":begin_tab:toc\n",
    " - [geometry-linear-algebraic-ops](geometry-linear-algebraic-ops.ipynb)\n",
    " - [eigendecomposition](eigendecomposition.ipynb)\n",
    " - [single-variable-calculus](single-variable-calculus.ipynb)\n",
    " - [multivariable-calculus](multivariable-calculus.ipynb)\n",
    " - [integral-calculus](integral-calculus.ipynb)\n",
    " - [random-variables](random-variables.ipynb)\n",
    " - [maximum-likelihood](maximum-likelihood.ipynb)\n",
    " - [distributions](distributions.ipynb)\n",
    " - [naive-bayes](naive-bayes.ipynb)\n",
    " - [statistics](statistics.ipynb)\n",
    " - [information-theory](information-theory.ipynb)\n",
    ":end_tab:"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "required_libs": []
 },
 "nbformat": 4,
 "nbformat_minor": 5
}