{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1c651b9",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# 几何与线性代数运算\n",
    ":label:`sec_geometry-linear-algebraic-ops`\n",
    "\n",
    "在 :numref:`sec_linear-algebra` 中，我们遇到了线性代数的基础知识，并看到了它如何用于表达转换数据的常见操作。线性代数是支撑我们在深度学习乃至更广泛的机器学习领域工作的关键数学支柱之一。虽然 :numref:`sec_linear-algebra` 包含了足够的机制来解释现代深度学习模型的运作原理，但这个主题还有很多内容。在这一节中，我们将深入探讨，突出一些线性代数运算的几何解释，并介绍几个基本概念，包括特征值和特征向量。\n",
    "\n",
    "## 向量的几何学\n",
    "首先，我们需要讨论向量的两种常见的几何解释，即作为空间中的点或方向。从根本上说，向量是一组数字，例如下面的 Python 列表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cacc74a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T19:30:00.057600Z",
     "iopub.status.busy": "2023-08-18T19:30:00.057050Z",
     "iopub.status.idle": "2023-08-18T19:30:00.065399Z",
     "shell.execute_reply": "2023-08-18T19:30:00.064455Z"
    },
    "origin_pos": 1,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "v = [1, 7, 0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112fc890",
   "metadata": {
    "origin_pos": 2
   },
   "source": [
    "数学家通常将这写成*列*向量或*行*向量，也就是说，\n",
    "\n",
    "$$\n",
    "\\mathbf{x} = \\begin{bmatrix}1\\\\7\\\\0\\\\1\\end{bmatrix},\n",
    "$$\n",
    "\n",
    "或者\n",
    "\n",
    "$$\n",
    "\\mathbf{x}^\\top = \\begin{bmatrix}1 & 7 & 0 & 1\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "这些经常有不同的解释，其中数据样本是列向量，而用于形成加权和的权重是行向量。然而，灵活处理是有益的。正如我们在 :numref:`sec_linear-algebra` 中所描述的那样，虽然单个向量的默认方向是列向量，但对于表示表格数据集的任何矩阵来说，将每个数据样本视为矩阵中的行向量更为常见。\n",
    "\n",
    "给定一个向量，我们首先应该将其视为空间中的一个点。在二维或三维中，我们可以通过使用向量的分量来定义相对于称为*原点*的固定参考的空间中的点的位置来可视化这些点。这可以在 :numref:`fig_grid` 中看到。\n",
    "\n",
    "![通过将向量的分量作为点在平面上进行可视化的一种说明。向量的第一个分量给出$\\mathit{x}$坐标，第二个分量给出$\\mathit{y}$坐标。更高维度的情况类似，尽管更难以可视化。](../img/grid-points.svg)\n",
    ":label:`fig_grid`\n",
    "\n",
    "这种几何观点允许我们从更抽象的层次考虑问题。不再面对像分类图片为猫或狗这样看似无法克服的问题，我们可以开始将任务抽象地视为空间中点的集合，并将任务想象为发现如何分离两个不同的点群。\n",
    "\n",
    "同时，人们对于向量常持有第二种观点：即作为空间中的方向。我们不仅可以将向量 $\\mathbf{v} = [3,2]^\\top$ 视为从原点向右 $3$ 单位、向上 $2$ 单位的位置，还可以将其视为本身的方向，即向右走 $3$ 步、向上走 $2$ 步。以这种方式，我们认为图 :numref:`fig_arrow` 中的所有向量都是相同的。\n",
    "\n",
    "![任何向量都可以被可视化为空中的箭头。在这个例子中，绘制的每个向量都代表向量 $(3,2)^\\top$。](../img/par-vec.svg)\n",
    ":label:`fig_arrow`\n",
    "\n",
    "这种转变的好处之一是我们可以直观理解向量相加的行为。特别是，我们先遵循一个向量给出的方向，然后跟随另一个向量给出的方向，如 :numref:`fig_add-vec` 所示。\n",
    "\n",
    "![我们可以通过先跟随一个向量再跟随另一个向量来可视化向量相加。](../img/vec-add.svg)\n",
    ":label:`fig_add-vec`\n",
    "\n",
    "向量减法有类似的解释。考虑到等式 $\\mathbf{u} = \\mathbf{v} + (\\mathbf{u}-\\mathbf{v})$，我们看到向量 $\\mathbf{u}-\\mathbf{v}$ 是从点 $\\mathbf{v}$ 到点 $\\mathbf{u}$ 的方向。\n",
    "\n",
    "\n",
    "## 点积与角度\n",
    "正如我们在 :numref:`sec_linear-algebra` 中看到的，如果我们取两个列向量 $\\mathbf{u}$ 和 $\\mathbf{v}$，我们可以通过计算形成它们的点积：\n",
    "\n",
    "$$\\mathbf{u}^\\top\\mathbf{v} = \\sum_i u_i\\cdot v_i.$$\n",
    ":eqlabel:`eq_dot_def`\n",
    "\n",
    "由于 :eqref:`eq_dot_def` 是对称的，我们将采用经典乘法符号并写作\n",
    "\n",
    "$$\n",
    "\\mathbf{u}\\cdot\\mathbf{v} = \\mathbf{u}^\\top\\mathbf{v} = \\mathbf{v}^\\top\\mathbf{u},\n",
    "$$\n",
    "\n",
    "以强调交换向量顺序会得到相同答案的事实。\n",
    "\n",
    "点积 :eqref:`eq_dot_def` 也承认几何解释：它与两向量之间的角度密切相关。考虑 :numref:`fig_angle` 中显示的角度。\n",
    "\n",
    "![平面内任意两个向量之间都有一个明确定义的角度 $\\theta$。我们将看到这个角度与点积紧密相关。](../img/vec-angle.svg)\n",
    ":label:`fig_angle`\n",
    "\n",
    "首先，让我们考虑两个特定的向量：\n",
    "\n",
    "$$\n",
    "\\mathbf{v} = (r,0) \\; \\textrm{和} \\; \\mathbf{w} = (s\\cos(\\theta), s \\sin(\\theta)).\n",
    "$$\n",
    "\n",
    "向量 $\\mathbf{v}$ 长度为 $r$ 并且平行于 $x$ 轴，而向量 $\\mathbf{w}$ 长度为 $s$ 并且与 $x$ 轴成 $\\theta$ 角。如果我们计算这两个向量的点积，我们会发现\n",
    "\n",
    "$$\n",
    "\\mathbf{v}\\cdot\\mathbf{w} = rs\\cos(\\theta) = \\|\\mathbf{v}\\|\\|\\mathbf{w}\\|\\cos(\\theta).\n",
    "$$\n",
    "\n",
    "通过一些简单的代数操作，我们可以重新排列项以获得\n",
    "\n",
    "$$\n",
    "\\theta = \\arccos\\left(\\frac{\\mathbf{v}\\cdot\\mathbf{w}}{\\|\\mathbf{v}\\|\\|\\mathbf{w}\\|}\\right).\n",
    "$$\n",
    "\n",
    "简而言之，对于这两个特定向量，点积结合范数告诉我们两向量之间的角度。这一事实一般成立。我们不会在这里推导表达式，但是，如果我们将 $\\|\\mathbf{v} - \\mathbf{w}\\|^2$ 用两种方式写出：一种是利用点积，另一种是利用余弦定律几何地写出，我们就可以得到完整的关系。确实，对于任意两个向量 $\\mathbf{v}$ 和 $\\mathbf{w}$，两向量之间的角度为\n",
    "\n",
    "$$\\theta = \\arccos\\left(\\frac{\\mathbf{v}\\cdot\\mathbf{w}}{\\|\\mathbf{v}\\|\\|\\mathbf{w}\\|}\\right).$$\n",
    ":eqlabel:`eq_angle_forumla`\n",
    "\n",
    "这是一个很好的结果，因为计算中没有任何部分引用了二维。实际上，我们可以在三维或三百万维中无问题地使用这个公式。\n",
    "\n",
    "作为一个简单的例子，让我们看看如何计算一对向量之间的角度："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c68a6de0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T19:30:00.068681Z",
     "iopub.status.busy": "2023-08-18T19:30:00.068407Z",
     "iopub.status.idle": "2023-08-18T19:30:03.242521Z",
     "shell.execute_reply": "2023-08-18T19:30:03.241359Z"
    },
    "origin_pos": 4,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4190)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torchvision\n",
    "from IPython import display\n",
    "from torchvision import transforms\n",
    "from d2l import torch as d2l\n",
    "\n",
    "\n",
    "def angle(v, w):\n",
    "    return torch.acos(v.dot(w) / (torch.norm(v) * torch.norm(w)))\n",
    "\n",
    "angle(torch.tensor([0, 1, 2], dtype=torch.float32), torch.tensor([2.0, 3, 4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41060004",
   "metadata": {
    "origin_pos": 6
   },
   "source": [
    "我们目前不会使用它，但了解这一点是有用的：我们将角度为 $\\pi/2$（或等效地 $90^{\\circ}$）的向量称为*正交*。通过检查上述方程，我们看到当 $\\theta = \\pi/2$ 时会发生这种情况，这与 $\\cos(\\theta) = 0$ 是同一件事。唯一可能发生这种情况的方式是点积本身为零，并且两个向量在且仅在 $\\mathbf{v}\\cdot\\mathbf{w} = 0$ 时正交。这个公式在理解对象几何形状时将被证明是有帮助的。\n",
    "\n",
    "问一个合理的问题：为什么计算角度有用？答案在于我们期望数据具有的不变性类型。考虑一张图片及其副本，其中每个像素值相同但亮度为原来的10%。单个像素的值通常远非原始值。因此，如果计算原始图像和较暗图像之间的距离，该距离可能很大。然而，对于大多数ML应用来说，*内容*是一样的——就猫/狗分类器而言，它仍然是一张猫的图片。然而，如果我们考虑角度，不难看出对于任何向量 $\\mathbf{v}$，$\\mathbf{v}$ 和 $0.1\\cdot\\mathbf{v}$ 之间的角度为零。这对应于缩放向量保持相同方向而只改变长度的事实。角度认为较暗的图像是相同的。\n",
    "\n",
    "这样的例子到处都是。在文本中，我们可能希望讨论的主题不会因为我们写了一篇说同样事情但长度翻倍的文档而改变。对于某些编码（例如统计词汇表中单词出现次数），这对应于文档向量的加倍，因此我们再次可以使用角度。\n",
    "\n",
    "### 余弦相似度\n",
    "在使用角度测量两个向量接近程度的ML上下文中，从业者采用术语*余弦相似度*来指代部分\n",
    "$$\n",
    "\\cos(\\theta) = \\frac{\\mathbf{v}\\cdot\\mathbf{w}}{\\|\\mathbf{v}\\|\\|\\mathbf{w}\\|}.\n",
    "$$\n",
    "\n",
    "当两个向量指向同一方向时，余弦取最大值1；当它们指向相反方向时，取最小值-1；当两个向量正交时，取值0。请注意，如果高维向量的分量以均值0随机采样，它们的余弦几乎总是接近0。\n",
    "\n",
    "## 超平面\n",
    "\n",
    "除了处理向量之外，另一个你必须理解才能在线性代数中走得更远的关键对象是*超平面*，它是对更高维度的线（二维）或平面（三维）的一般化。在$d$维向量空间中，超平面具有$d-1$维并将空间分为两个半空间。\n",
    "\n",
    "让我们从一个例子开始。假设我们有一个列向量$\\mathbf{w}=[2,1]^\\top$。我们想知道，“哪些点$\\mathbf{v}$满足$\\mathbf{w}\\cdot\\mathbf{v} = 1$？”通过回忆上面的角度与点积的关系:eqref:`eq_angle_forumla`，我们可以看到这等价于\n",
    "$$\n",
    "\\|\\mathbf{v}\\|\\|\\mathbf{w}\\|\\cos(\\theta) = 1 \\; \\iff \\; \\|\\mathbf{v}\\|\\cos(\\theta) = \\frac{1}{\\|\\mathbf{w}\\|} = \\frac{1}{\\sqrt{5}}.\n",
    "$$\n",
    "\n",
    "![回顾三角学，我们看到公式$\\|\\mathbf{v}\\|\\cos(\\theta)$是向量$\\mathbf{v}$在$\\mathbf{w}$方向上的投影长度](../img/proj-vec.svg)\n",
    ":label:`fig_vector-project`\n",
    "\n",
    "如果我们考虑此表达式的几何意义，我们会发现这相当于说$\\mathbf{v}$在$\\mathbf{w}$方向上的投影长度恰好为$1/\\|\\mathbf{w}\\|$，如:numref:`fig_vector-project`所示。所有满足这一条件的点构成一条与向量$\\mathbf{w}$垂直的直线。如果我们愿意，我们可以找到这条直线的方程并看到它是$2x + y = 1$或等效地$y = 1 - 2x$。\n",
    "\n",
    "现在，如果我们看看当我们询问$\\mathbf{w}\\cdot\\mathbf{v} > 1$或$\\mathbf{w}\\cdot\\mathbf{v} < 1$的点集时会发生什么，我们可以看到这些是投影长于或短于$1/\\|\\mathbf{w}\\|$的情况。因此，这两个不等式定义了线的两侧。这样，我们就找到了一种将空间切成两半的方法，其中一侧的所有点的点积低于阈值，另一侧则高于阈值，如:numref:`fig_space-division`所示。\n",
    "\n",
    "![现在，如果我们考虑表达式的不等式版本，我们看到我们的超平面（在这种情况下：只是一条线）将空间分成两半。](../img/space-division.svg)\n",
    ":label:`fig_space-division`\n",
    "\n",
    "在更高维度的故事大致相同。如果我们现在取$\\mathbf{w} = [1,2,3]^\\top$并询问三维中满足$\\mathbf{w}\\cdot\\mathbf{v} = 1$的点，我们获得了一个与给定向量$\\mathbf{w}$垂直的平面。两个不等式再次定义了平面的两侧，如:numref:`fig_higher-division`所示。\n",
    "\n",
    "![在任何维度上，超平面都将空间分成两半。](../img/space-division-3d.svg)\n",
    ":label:`fig_higher-division`\n",
    "\n",
    "虽然我们的可视化能力到此为止，但这不妨碍我们在数十、数百甚至数十亿维度上这样做。这种情况经常出现在思考机器学习模型时。例如，我们可以理解像:numref:`sec_softmax`中的线性分类模型，作为找到区分不同目标类别的超平面的方法。在此背景下，这样的超平面通常被称为*决策平面*。大多数深度学习分类模型以一个线性层输入softmax结束，因此可以解释深度神经网络的作用是找到一个非线性嵌入，使得目标类别能够由超平面清晰地区分。\n",
    "\n",
    "为了提供一个手工构建的例子，请注意我们可以通过简单地取Fashion-MNIST数据集（见:numref:`sec_fashion_mnist`）中的T恤和裤子之间均值的向量来定义决策平面，并粗略估计一个阈值，从而产生一个合理的模型来对这些小图像进行分类。首先我们将加载数据并计算平均值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6181ed73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T19:30:03.247622Z",
     "iopub.status.busy": "2023-08-18T19:30:03.246701Z",
     "iopub.status.idle": "2023-08-18T19:30:28.056683Z",
     "shell.execute_reply": "2023-08-18T19:30:28.055314Z"
    },
    "origin_pos": 8,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "# Load in the dataset\n",
    "trans = []\n",
    "trans.append(transforms.ToTensor())\n",
    "trans = transforms.Compose(trans)\n",
    "train = torchvision.datasets.FashionMNIST(root=\"../data\", transform=trans,\n",
    "                                          train=True, download=True)\n",
    "test = torchvision.datasets.FashionMNIST(root=\"../data\", transform=trans,\n",
    "                                         train=False, download=True)\n",
    "\n",
    "X_train_0 = torch.stack(\n",
    "    [x[0] * 256 for x in train if x[1] == 0]).type(torch.float32)\n",
    "X_train_1 = torch.stack(\n",
    "    [x[0] * 256 for x in train if x[1] == 1]).type(torch.float32)\n",
    "X_test = torch.stack(\n",
    "    [x[0] * 256 for x in test if x[1] == 0 or x[1] == 1]).type(torch.float32)\n",
    "y_test = torch.stack([torch.tensor(x[1]) for x in test\n",
    "                      if x[1] == 0 or x[1] == 1]).type(torch.float32)\n",
    "\n",
    "# Compute averages\n",
    "ave_0 = torch.mean(X_train_0, axis=0)\n",
    "ave_1 = torch.mean(X_train_1, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269eb648",
   "metadata": {
    "origin_pos": 10
   },
   "source": [
    "仔细查看这些平均值会很有启发性，所以让我们绘制出它们的样子。在这种情况下，我们看到平均值确实像一件T恤的模糊图像。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "027037c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T19:30:28.063623Z",
     "iopub.status.busy": "2023-08-18T19:30:28.061532Z",
     "iopub.status.idle": "2023-08-18T19:30:28.243347Z",
     "shell.execute_reply": "2023-08-18T19:30:28.242495Z"
    },
    "origin_pos": 11,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"172.725pt\" height=\"171.002344pt\" viewBox=\"0 0 172.725 171.002344\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2023-08-18T19:30:28.191114</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.7.2, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 171.002344 \n",
       "L 172.725 171.002344 \n",
       "L 172.725 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 26.925 147.124219 \n",
       "L 165.525 147.124219 \n",
       "L 165.525 8.524219 \n",
       "L 26.925 8.524219 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g clip-path=\"url(#p092a295790)\">\n",
       "    <image xlink:href=\"data:image/png;base64,\n",
       "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\" id=\"image09286d7aa5\" transform=\"scale(1 -1) translate(0 -138.96)\" x=\"26.925\" y=\"-8.164219\" width=\"138.96\" height=\"138.96\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <defs>\n",
       "       <path id=\"mac3d2c90d8\" d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#mac3d2c90d8\" x=\"29.4\" y=\"147.124219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(26.21875 161.722656) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \n",
       "Q 1547 4250 1301 3770 \n",
       "Q 1056 3291 1056 2328 \n",
       "Q 1056 1369 1301 889 \n",
       "Q 1547 409 2034 409 \n",
       "Q 2525 409 2770 889 \n",
       "Q 3016 1369 3016 2328 \n",
       "Q 3016 3291 2770 3770 \n",
       "Q 2525 4250 2034 4250 \n",
       "z\n",
       "M 2034 4750 \n",
       "Q 2819 4750 3233 4129 \n",
       "Q 3647 3509 3647 2328 \n",
       "Q 3647 1150 3233 529 \n",
       "Q 2819 -91 2034 -91 \n",
       "Q 1250 -91 836 529 \n",
       "Q 422 1150 422 2328 \n",
       "Q 422 3509 836 4129 \n",
       "Q 1250 4750 2034 4750 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mac3d2c90d8\" x=\"78.9\" y=\"147.124219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 10 -->\n",
       "      <g transform=\"translate(72.5375 161.722656) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-31\" d=\"M 794 531 \n",
       "L 1825 531 \n",
       "L 1825 4091 \n",
       "L 703 3866 \n",
       "L 703 4441 \n",
       "L 1819 4666 \n",
       "L 2450 4666 \n",
       "L 2450 531 \n",
       "L 3481 531 \n",
       "L 3481 0 \n",
       "L 794 0 \n",
       "L 794 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mac3d2c90d8\" x=\"128.4\" y=\"147.124219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 20 -->\n",
       "      <g transform=\"translate(122.0375 161.722656) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \n",
       "L 3431 531 \n",
       "L 3431 0 \n",
       "L 469 0 \n",
       "L 469 531 \n",
       "Q 828 903 1448 1529 \n",
       "Q 2069 2156 2228 2338 \n",
       "Q 2531 2678 2651 2914 \n",
       "Q 2772 3150 2772 3378 \n",
       "Q 2772 3750 2511 3984 \n",
       "Q 2250 4219 1831 4219 \n",
       "Q 1534 4219 1204 4116 \n",
       "Q 875 4013 500 3803 \n",
       "L 500 4441 \n",
       "Q 881 4594 1212 4672 \n",
       "Q 1544 4750 1819 4750 \n",
       "Q 2544 4750 2975 4387 \n",
       "Q 3406 4025 3406 3419 \n",
       "Q 3406 3131 3298 2873 \n",
       "Q 3191 2616 2906 2266 \n",
       "Q 2828 2175 2409 1742 \n",
       "Q 1991 1309 1228 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <defs>\n",
       "       <path id=\"mb4bd03e6c6\" d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#mb4bd03e6c6\" x=\"26.925\" y=\"10.999219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(13.5625 14.798437) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mb4bd03e6c6\" x=\"26.925\" y=\"35.749219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 5 -->\n",
       "      <g transform=\"translate(13.5625 39.548437) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \n",
       "L 3169 4666 \n",
       "L 3169 4134 \n",
       "L 1269 4134 \n",
       "L 1269 2991 \n",
       "Q 1406 3038 1543 3061 \n",
       "Q 1681 3084 1819 3084 \n",
       "Q 2600 3084 3056 2656 \n",
       "Q 3513 2228 3513 1497 \n",
       "Q 3513 744 3044 326 \n",
       "Q 2575 -91 1722 -91 \n",
       "Q 1428 -91 1123 -41 \n",
       "Q 819 9 494 109 \n",
       "L 494 744 \n",
       "Q 775 591 1075 516 \n",
       "Q 1375 441 1709 441 \n",
       "Q 2250 441 2565 725 \n",
       "Q 2881 1009 2881 1497 \n",
       "Q 2881 1984 2565 2268 \n",
       "Q 2250 2553 1709 2553 \n",
       "Q 1456 2553 1204 2497 \n",
       "Q 953 2441 691 2322 \n",
       "L 691 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-35\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mb4bd03e6c6\" x=\"26.925\" y=\"60.499219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 10 -->\n",
       "      <g transform=\"translate(7.2 64.298437) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mb4bd03e6c6\" x=\"26.925\" y=\"85.249219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 15 -->\n",
       "      <g transform=\"translate(7.2 89.048437) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mb4bd03e6c6\" x=\"26.925\" y=\"109.999219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 20 -->\n",
       "      <g transform=\"translate(7.2 113.798437) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mb4bd03e6c6\" x=\"26.925\" y=\"134.749219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 25 -->\n",
       "      <g transform=\"translate(7.2 138.548437) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 26.925 147.124219 \n",
       "L 26.925 8.524219 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 165.525 147.124219 \n",
       "L 165.525 8.524219 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 26.925 147.124219 \n",
       "L 165.525 147.124219 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 26.925 8.524219 \n",
       "L 165.525 8.524219 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p092a295790\">\n",
       "   <rect x=\"26.925\" y=\"8.524219\" width=\"138.6\" height=\"138.6\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 350x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot average t-shirt\n",
    "d2l.set_figsize()\n",
    "d2l.plt.imshow(ave_0.reshape(28, 28).tolist(), cmap='Greys')\n",
    "d2l.plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed0be84",
   "metadata": {
    "origin_pos": 13
   },
   "source": [
    "在第二种情况下，我们再次看到平均结果类似于裤子的模糊图像。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "909256ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T19:30:28.247745Z",
     "iopub.status.busy": "2023-08-18T19:30:28.246995Z",
     "iopub.status.idle": "2023-08-18T19:30:28.422205Z",
     "shell.execute_reply": "2023-08-18T19:30:28.421098Z"
    },
    "origin_pos": 14,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"172.725pt\" height=\"171.002344pt\" viewBox=\"0 0 172.725 171.002344\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2023-08-18T19:30:28.379952</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.7.2, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 171.002344 \n",
       "L 172.725 171.002344 \n",
       "L 172.725 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 26.925 147.124219 \n",
       "L 165.525 147.124219 \n",
       "L 165.525 8.524219 \n",
       "L 26.925 8.524219 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g clip-path=\"url(#p540c0124e8)\">\n",
       "    <image xlink:href=\"data:image/png;base64,\n",
       "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\" id=\"image1a2ad3002d\" transform=\"scale(1 -1) translate(0 -138.96)\" x=\"26.925\" y=\"-8.164219\" width=\"138.96\" height=\"138.96\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <defs>\n",
       "       <path id=\"mc35d0f60bf\" d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#mc35d0f60bf\" x=\"29.4\" y=\"147.124219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(26.21875 161.722656) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \n",
       "Q 1547 4250 1301 3770 \n",
       "Q 1056 3291 1056 2328 \n",
       "Q 1056 1369 1301 889 \n",
       "Q 1547 409 2034 409 \n",
       "Q 2525 409 2770 889 \n",
       "Q 3016 1369 3016 2328 \n",
       "Q 3016 3291 2770 3770 \n",
       "Q 2525 4250 2034 4250 \n",
       "z\n",
       "M 2034 4750 \n",
       "Q 2819 4750 3233 4129 \n",
       "Q 3647 3509 3647 2328 \n",
       "Q 3647 1150 3233 529 \n",
       "Q 2819 -91 2034 -91 \n",
       "Q 1250 -91 836 529 \n",
       "Q 422 1150 422 2328 \n",
       "Q 422 3509 836 4129 \n",
       "Q 1250 4750 2034 4750 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mc35d0f60bf\" x=\"78.9\" y=\"147.124219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 10 -->\n",
       "      <g transform=\"translate(72.5375 161.722656) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-31\" d=\"M 794 531 \n",
       "L 1825 531 \n",
       "L 1825 4091 \n",
       "L 703 3866 \n",
       "L 703 4441 \n",
       "L 1819 4666 \n",
       "L 2450 4666 \n",
       "L 2450 531 \n",
       "L 3481 531 \n",
       "L 3481 0 \n",
       "L 794 0 \n",
       "L 794 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mc35d0f60bf\" x=\"128.4\" y=\"147.124219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 20 -->\n",
       "      <g transform=\"translate(122.0375 161.722656) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \n",
       "L 3431 531 \n",
       "L 3431 0 \n",
       "L 469 0 \n",
       "L 469 531 \n",
       "Q 828 903 1448 1529 \n",
       "Q 2069 2156 2228 2338 \n",
       "Q 2531 2678 2651 2914 \n",
       "Q 2772 3150 2772 3378 \n",
       "Q 2772 3750 2511 3984 \n",
       "Q 2250 4219 1831 4219 \n",
       "Q 1534 4219 1204 4116 \n",
       "Q 875 4013 500 3803 \n",
       "L 500 4441 \n",
       "Q 881 4594 1212 4672 \n",
       "Q 1544 4750 1819 4750 \n",
       "Q 2544 4750 2975 4387 \n",
       "Q 3406 4025 3406 3419 \n",
       "Q 3406 3131 3298 2873 \n",
       "Q 3191 2616 2906 2266 \n",
       "Q 2828 2175 2409 1742 \n",
       "Q 1991 1309 1228 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <defs>\n",
       "       <path id=\"ma192f08d88\" d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#ma192f08d88\" x=\"26.925\" y=\"10.999219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(13.5625 14.798437) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#ma192f08d88\" x=\"26.925\" y=\"35.749219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 5 -->\n",
       "      <g transform=\"translate(13.5625 39.548437) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \n",
       "L 3169 4666 \n",
       "L 3169 4134 \n",
       "L 1269 4134 \n",
       "L 1269 2991 \n",
       "Q 1406 3038 1543 3061 \n",
       "Q 1681 3084 1819 3084 \n",
       "Q 2600 3084 3056 2656 \n",
       "Q 3513 2228 3513 1497 \n",
       "Q 3513 744 3044 326 \n",
       "Q 2575 -91 1722 -91 \n",
       "Q 1428 -91 1123 -41 \n",
       "Q 819 9 494 109 \n",
       "L 494 744 \n",
       "Q 775 591 1075 516 \n",
       "Q 1375 441 1709 441 \n",
       "Q 2250 441 2565 725 \n",
       "Q 2881 1009 2881 1497 \n",
       "Q 2881 1984 2565 2268 \n",
       "Q 2250 2553 1709 2553 \n",
       "Q 1456 2553 1204 2497 \n",
       "Q 953 2441 691 2322 \n",
       "L 691 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-35\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#ma192f08d88\" x=\"26.925\" y=\"60.499219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 10 -->\n",
       "      <g transform=\"translate(7.2 64.298437) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#ma192f08d88\" x=\"26.925\" y=\"85.249219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 15 -->\n",
       "      <g transform=\"translate(7.2 89.048437) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#ma192f08d88\" x=\"26.925\" y=\"109.999219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 20 -->\n",
       "      <g transform=\"translate(7.2 113.798437) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#ma192f08d88\" x=\"26.925\" y=\"134.749219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 25 -->\n",
       "      <g transform=\"translate(7.2 138.548437) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 26.925 147.124219 \n",
       "L 26.925 8.524219 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 165.525 147.124219 \n",
       "L 165.525 8.524219 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 26.925 147.124219 \n",
       "L 165.525 147.124219 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 26.925 8.524219 \n",
       "L 165.525 8.524219 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p540c0124e8\">\n",
       "   <rect x=\"26.925\" y=\"8.524219\" width=\"138.6\" height=\"138.6\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 350x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot average trousers\n",
    "d2l.plt.imshow(ave_1.reshape(28, 28).tolist(), cmap='Greys')\n",
    "d2l.plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cae38cb",
   "metadata": {
    "origin_pos": 16
   },
   "source": [
    "在完全基于机器学习的解决方案中，我们会从数据集中学习阈值。在这种情况下，我只是手动选择了一个在训练数据上看起来不错的阈值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "608ae3a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T19:30:28.426733Z",
     "iopub.status.busy": "2023-08-18T19:30:28.425880Z",
     "iopub.status.idle": "2023-08-18T19:30:28.442336Z",
     "shell.execute_reply": "2023-08-18T19:30:28.440892Z"
    },
    "origin_pos": 18,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7870, dtype=torch.float64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print test set accuracy with eyeballed threshold\n",
    "w = (ave_1 - ave_0).T\n",
    "# '@' is Matrix Multiplication operator in pytorch.\n",
    "predictions = X_test.reshape(2000, -1) @ (w.flatten()) > -1500000\n",
    "\n",
    "# Accuracy\n",
    "torch.mean((predictions.type(y_test.dtype) == y_test).float(), dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d75c35",
   "metadata": {
    "origin_pos": 20
   },
   "source": [
    "## 线性变换的几何\n",
    "\n",
    "通过 :numref:`sec_linear-algebra` 和上述讨论，我们对向量、长度和角度的几何有了扎实的理解。然而，有一个重要的对象我们还没有讨论过，那就是矩阵所代表的线性变换的几何理解。完全内化矩阵如何在两个可能不同的高维空间之间转换数据需要大量的实践，并且超出了本附录的范围。但是，我们可以从二维开始建立直觉。\n",
    "\n",
    "假设我们有一些矩阵：\n",
    "\n",
    "$$\n",
    "\\mathbf{A} = \\begin{bmatrix}\n",
    "a & b \\\\ c & d\n",
    "\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "如果我们想将这个矩阵应用到任意向量 $\\mathbf{v} = [x, y]^\\top$ 上，我们进行乘法运算并看到\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathbf{A}\\mathbf{v} & = \\begin{bmatrix}a & b \\\\ c & d\\end{bmatrix}\\begin{bmatrix}x \\\\ y\\end{bmatrix} \\\\\n",
    "& = \\begin{bmatrix}ax+by\\\\ cx+dy\\end{bmatrix} \\\\\n",
    "& = x\\begin{bmatrix}a \\\\ c\\end{bmatrix} + y\\begin{bmatrix}b \\\\d\\end{bmatrix} \\\\\n",
    "& = x\\left\\{\\mathbf{A}\\begin{bmatrix}1\\\\0\\end{bmatrix}\\right\\} + y\\left\\{\\mathbf{A}\\begin{bmatrix}0\\\\1\\end{bmatrix}\\right\\}.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "这看起来像是一个奇怪的计算，清晰的东西变得有些难以理解。然而，它告诉我们，我们可以用矩阵如何变换*两个特定向量*来表示矩阵如何变换*任何向量*：$[1,0]^\\top$ 和 $[0,1]^\\top$。这值得考虑一下。我们实际上已经把一个无限的问题（任何一对实数会发生什么）简化成了一个有限的问题（这些特定向量会发生什么）。这些向量是一个*基*的例子，我们可以将空间中的任何向量写成这些*基向量*的加权和。\n",
    "\n",
    "让我们画出使用特定矩阵时的情况\n",
    "\n",
    "$$\n",
    "\\mathbf{A} = \\begin{bmatrix}\n",
    "1 & 2 \\\\\n",
    "-1 & 3\n",
    "\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "如果我们看特定向量 $\\mathbf{v} = [2, -1]^\\top$，我们看到这是 $2\\cdot[1,0]^\\top + -1\\cdot[0,1]^\\top$，因此我们知道矩阵 $A$ 会将其发送到 $2(\\mathbf{A}[1,0]^\\top) + -1(\\mathbf{A}[0,1])^\\top = 2[1, -1]^\\top - [2,3]^\\top = [0, -5]^\\top$。如果我们仔细遵循这个逻辑，比如说通过考虑所有整数对点的网格，我们会看到发生的事情是矩阵乘法可以扭曲、旋转和平移网格，但网格结构必须保持如你所见在 :numref:`fig_grid-transform` 中。\n",
    "\n",
    "![矩阵 $\\mathbf{A}$ 作用于给定的基向量。请注意整个网格是如何随之移动的。](../img/grid-transform.svg)\n",
    ":label:`fig_grid-transform`\n",
    "\n",
    "这是关于由矩阵表示的线性变换最重要的直观理解点。矩阵无法以不同方式扭曲空间的不同部分。它们所能做的就是取原始坐标并对其进行扭曲、旋转和平移。\n",
    "\n",
    "某些扭曲可能是严重的。例如矩阵\n",
    "\n",
    "$$\n",
    "\\mathbf{B} = \\begin{bmatrix}\n",
    "2 & -1 \\\\ 4 & -2\n",
    "\\end{bmatrix},\n",
    "$$\n",
    "\n",
    "将整个二维平面压缩到一条线上。识别和处理这种变换是后面章节的主题，但从几何上看，这与我们在上面看到的变换类型有根本不同。例如，来自矩阵 $\\mathbf{A}$ 的结果可以“弯曲回”原来的网格。来自矩阵 $\\mathbf{B}$ 的结果则不能，因为我们永远不知道向量 $[1,2]^\\top$ 是从哪里来的——它是 $[1,1]^\\top$ 还是 $[0, -1]^\\top$？\n",
    "\n",
    "虽然这个图示是针对 $2\\times2$ 矩阵的，但这并不妨碍我们将学到的经验推广到更高维度。如果我们取类似的基向量如 $[1,0, \\ldots,0]$ 并查看我们的矩阵将它们发送到哪里，我们可以开始感受到矩阵乘法如何在我们正在处理的任何维度空间中扭曲整个空间。\n",
    "\n",
    "## 线性相关\n",
    "\n",
    "再次考虑矩阵\n",
    "\n",
    "$$\n",
    "\\mathbf{B} = \\begin{bmatrix}\n",
    "2 & -1 \\\\ 4 & -2\n",
    "\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "这将整个平面压缩到单一线 $y = 2x$ 上。现在的问题是：是否有办法仅仅通过观察矩阵本身就能检测到这一点？答案是确实可以。让我们取 $\\mathbf{b}_1 = [2,4]^\\top$ 和 $\\mathbf{b}_2 = [-1, -2]^\\top$ 作为矩阵 $\\mathbf{B}$ 的两列。记住，我们可以将被矩阵 $\\mathbf{B}$ 变换的所有内容写成矩阵列的加权和：如 $a_1\\mathbf{b}_1 + a_2\\mathbf{b}_2$。我们称其为*线性组合*。$\\mathbf{b}_1 = -2\\cdot\\mathbf{b}_2$ 的事实意味着我们可以将这两列的任何线性组合完全用比如 $\\mathbf{b}_2$ 来表示，因为\n",
    "\n",
    "$$\n",
    "a_1\\mathbf{b}_1 + a_2\\mathbf{b}_2 = -2a_1\\mathbf{b}_2 + a_2\\mathbf{b}_2 = (a_2-2a_1)\\mathbf{b}_2.\n",
    "$$\n",
    "\n",
    "这意味着其中一列在某种意义上是多余的，因为它没有定义空间中的唯一方向。这不应该让我们太惊讶，因为我们已经看到该矩阵将整个平面压缩到了一条线上。此外，我们看到线性相关 $\\mathbf{b}_1 = -2\\cdot\\mathbf{b}_2$ 捕捉到了这一点。为了使这两个向量之间的关系更对称，我们将写作\n",
    "\n",
    "$$\n",
    "\\mathbf{b}_1  + 2\\cdot\\mathbf{b}_2 = 0.\n",
    "$$\n",
    "\n",
    "一般来说，如果存在系数 $a_1, \\ldots, a_k$ *不全为零* 使得\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^k a_i\\mathbf{v_i} = 0,\n",
    "$$\n",
    "\n",
    "我们将会说向量集合 $\\mathbf{v}_1, \\ldots, \\mathbf{v}_k$ 是*线性相关的*。在这种情况下，我们可以用其他向量的组合来解出其中一个向量，从而有效地使其多余。因此，矩阵列中的线性相关性是矩阵将空间压缩到更低维度的证据。如果没有线性相关性，我们说向量是*线性无关的*。如果矩阵的列是线性无关的，则不会发生压缩，操作可以撤销。\n",
    "\n",
    "## 秩\n",
    "\n",
    "如果我们有一个一般的 $n\\times m$ 矩阵，问这个矩阵映射到哪个维度的空间是合理的。一个称为*秩*的概念将是我们要找的答案。在上一节中，我们注意到线性相关性表明空间被压缩到了更低维度，因此我们将能够利用这一点来定义秩的概念。特别地，矩阵 $\\mathbf{A}$ 的秩是在所有列子集中的最大线性无关列数。例如，矩阵\n",
    "\n",
    "$$\n",
    "\\mathbf{B} = \\begin{bmatrix}\n",
    "2 & 4 \\\\ -1 & -2\n",
    "\\end{bmatrix},\n",
    "$$\n",
    "\n",
    "具有 $\\textrm{rank}(B)=1$，因为两列是线性相关的，但单独的任一列不是线性相关的。对于一个更具挑战性的例子，我们可以考虑\n",
    "\n",
    "$$\n",
    "\\mathbf{C} = \\begin{bmatrix}\n",
    "1& 3 & 0 & -1 & 0 \\\\\n",
    "-1 & 0 & 1 & 1 & -1 \\\\\n",
    "0 & 3 & 1 & 0 & -1 \\\\\n",
    "2 & 3 & -1 & -2 & 1\n",
    "\\end{bmatrix},\n",
    "$$\n",
    "\n",
    "并展示 $\\mathbf{C}$ 具有秩二，因为例如前两列是线性无关的，然而任何三列的四个集合都是依赖的。\n",
    "\n",
    "正如描述的过程，这种方法非常低效。它要求查看给定矩阵的每一列子集，因此潜在地是列数的指数级。稍后我们将看到一种更高效的计算矩阵秩的方法，但现在，这足以看到概念是明确定义的并理解其含义。\n",
    "\n",
    "## 可逆性\n",
    "\n",
    "我们已经看到，具有线性相关列的矩阵的乘法是不可逆的，即没有总是可以恢复输入的逆操作。然而，满秩矩阵（即某个 $n \\times n$ 矩阵且秩为 $n$）的乘法应该总是可以撤销的。考虑矩阵\n",
    "\n",
    "$$\n",
    "\\mathbf{I} = \\begin{bmatrix}\n",
    "1 & 0 & \\cdots & 0 \\\\\n",
    "0 & 1 & \\cdots & 0 \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "0 & 0 & \\cdots & 1\n",
    "\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "这是一个对角线为 1，其余位置为 0 的矩阵。我们称其为*单位矩阵*。它是应用后不会改变数据的矩阵。要找到一个可以撤销矩阵 $\\mathbf{A}$ 所做操作的矩阵，我们需要找到一个矩阵 $\\mathbf{A}^{-1}$ 使得\n",
    "\n",
    "$$\n",
    "\\mathbf{A}^{-1}\\mathbf{A} = \\mathbf{A}\\mathbf{A}^{-1} =  \\mathbf{I}.\n",
    "$$\n",
    "\n",
    "如果我们把这个看作一个系统，我们有 $n \\times n$ 个未知数（$\\mathbf{A}^{-1}$ 的条目）和 $n \\times n$ 个方程（$\\mathbf{A}^{-1}\\mathbf{A}$ 的每个条目和 $\\mathbf{I}$ 的每个条目之间必须相等的等式），所以我们通常期望存在一个解。事实上，在下一节中我们将看到一个称为*行列式*的量，只要行列式不为零，我们就可以找到解。我们称这样的矩阵 $\\mathbf{A}^{-1}$ 为*逆矩阵*。作为一个例子，如果 $\\mathbf{A}$ 是一般 $2 \\times 2$ 矩阵\n",
    "\n",
    "$$\n",
    "\\mathbf{A} = \\begin{bmatrix}\n",
    "a & b \\\\\n",
    "c & d\n",
    "\\end{bmatrix},\n",
    "$$\n",
    "\n",
    "那么我们可以看到逆矩阵是\n",
    "\n",
    "$$\n",
    " \\frac{1}{ad-bc}  \\begin{bmatrix}\n",
    "d & -b \\\\\n",
    "-c & a\n",
    "\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "我们可以通过实际测试来看到，按上述公式给出的逆矩阵确实有效。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce241194",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T19:30:28.446491Z",
     "iopub.status.busy": "2023-08-18T19:30:28.445780Z",
     "iopub.status.idle": "2023-08-18T19:30:28.455103Z",
     "shell.execute_reply": "2023-08-18T19:30:28.453835Z"
    },
    "origin_pos": 22,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0.],\n",
       "        [0., 1.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = torch.tensor([[1, 2], [1, 4]], dtype=torch.float32)\n",
    "M_inv = torch.tensor([[2, -1], [-0.5, 0.5]])\n",
    "M_inv @ M"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e135d68f",
   "metadata": {
    "origin_pos": 24
   },
   "source": [
    "### 数值问题\n",
    "虽然矩阵的逆在理论上很有用，\n",
    "但我们必须说，在实践中大多数时候我们并不希望\n",
    "使用矩阵逆来解决问题。\n",
    "一般来说，解线性方程如\n",
    "\n",
    "$$\n",
    "\\mathbf{A}\\mathbf{x} = \\mathbf{b},\n",
    "$$\n",
    "\n",
    "有比计算逆矩阵并乘以得到\n",
    "\n",
    "$$\n",
    "\\mathbf{x} = \\mathbf{A}^{-1}\\mathbf{b}.\n",
    "$$\n",
    "\n",
    "更为数值稳定的算法。\n",
    "\n",
    "就像除以一个小数可能导致数值不稳定一样，\n",
    "接近低秩的矩阵求逆也可能导致数值不稳定。\n",
    "\n",
    "此外，通常矩阵$\\mathbf{A}$是*稀疏*的，\n",
    "也就是说它只包含少量非零值。\n",
    "如果我们研究一些例子，我们会发现\n",
    "这并不意味着逆矩阵也是稀疏的。\n",
    "即使$\\mathbf{A}$是一个$100$万乘以$100$万的矩阵\n",
    "只有$500$万个非零元素\n",
    "（因此我们只需要存储这$500$万个），\n",
    "其逆矩阵通常几乎每个元素都是非零的，\n",
    "需要我们存储所有$1\\textrm{M}^2$个元素---即$1$万亿个元素！\n",
    "\n",
    "虽然我们没有时间深入探讨在线性代数中\n",
    "经常遇到的所有棘手的数值问题，\n",
    "但我们想为您提供一些关于何时需要谨慎行事的直觉，\n",
    "通常避免在实践中求逆是一个很好的经验法则。\n",
    "\n",
    "## 行列式\n",
    "线性代数的几何视角提供了一种直观的方式来解释一个称为*行列式*的基本量。\n",
    "考虑之前的网格图像，但现在有一个突出显示的区域（:numref:`fig_grid-filled`）。\n",
    "\n",
    "![矩阵$\\mathbf{A}$再次扭曲了网格。这一次，我想特别指出高亮显示的正方形发生了什么变化。](../img/grid-transform-filled.svg)\n",
    ":label:`fig_grid-filled`\n",
    "\n",
    "看看高亮显示的正方形。这是一个边由$(0, 1)$和$(1, 0)$给出的正方形，因此它的面积为一。\n",
    "经过$\\mathbf{A}$变换后，\n",
    "我们看到它变成了一个平行四边形。\n",
    "这个平行四边形没有理由保持原来的面积，\n",
    "实际上，在这里展示的具体情况下\n",
    "\n",
    "$$\n",
    "\\mathbf{A} = \\begin{bmatrix}\n",
    "1 & 2 \\\\\n",
    "-1 & 3\n",
    "\\end{bmatrix},\n",
    "$$\n",
    "\n",
    "通过坐标几何计算\n",
    "可以得出该平行四边形的面积为$5$。\n",
    "\n",
    "一般而言，如果我们有一个矩阵\n",
    "\n",
    "$$\n",
    "\\mathbf{A} = \\begin{bmatrix}\n",
    "a & b \\\\\n",
    "c & d\n",
    "\\end{bmatrix},\n",
    "$$\n",
    "\n",
    "我们可以计算出结果平行四边形的面积为$ad-bc$。\n",
    "这个面积被称为*行列式*。\n",
    "\n",
    "让我们快速用一些示例代码检查一下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42a61cd7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T19:30:28.460420Z",
     "iopub.status.busy": "2023-08-18T19:30:28.459512Z",
     "iopub.status.idle": "2023-08-18T19:30:28.468439Z",
     "shell.execute_reply": "2023-08-18T19:30:28.467020Z"
    },
    "origin_pos": 26,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.det(torch.tensor([[1, -1], [2, 3]], dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d888e4",
   "metadata": {
    "origin_pos": 28
   },
   "source": [
    "眼尖的人会注意到，这个表达式可以为零甚至为负。对于负数项，这是一个惯例问题，在数学中通常这样处理：如果矩阵翻转了图形，我们说面积被取反。现在让我们看看当行列式为零时，我们会学到更多。\n",
    "\n",
    "考虑\n",
    "\n",
    "$$\n",
    "\\mathbf{B} = \\begin{bmatrix}\n",
    "2 & 4 \\\\ -1 & -2\n",
    "\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "如果我们计算这个矩阵的行列式，我们得到$2\\cdot(-2) - 4\\cdot(-1) = 0$。根据上面的理解，这是有道理的。$\\mathbf{B}$将原图像中的正方形压缩成一条线段，其面积为零。实际上，被压缩到更低维度的空间是变换后面积为零的唯一方式。因此我们看到以下结果是正确的：一个矩阵$A$可逆当且仅当行列式不等于零。\n",
    "\n",
    "最后补充一点，想象我们在平面上画了一个任意图形。像计算机科学家一样思考，我们可以把这个图形分解成一系列小正方形，这样图形的面积基本上就是这些小正方形的数量。如果现在用一个矩阵变换这个图形，我们将每个这样的正方形变换成平行四边形，每个平行四边形的面积由行列式给出。我们看到，对于任何图形，行列式给出了矩阵按比例缩放任何图形面积的（带符号的）数值。\n",
    "\n",
    "对于更大的矩阵计算行列式可能很繁琐，但直觉是一样的。行列式仍然是$n\\times n$矩阵缩放$n$维体积的因素。\n",
    "\n",
    "## 张量和常见的线性代数运算\n",
    "\n",
    "在 :numref:`sec_linear-algebra` 中介绍了张量的概念。在本节中，我们将更深入地探讨张量收缩（张量等同于矩阵乘法），并看到它如何提供一系列矩阵和向量运算的统一视图。\n",
    "\n",
    "对于矩阵和向量，我们知道如何通过它们相乘来转换数据。如果张量对我们有用，我们也需要对它们有一个类似的定义。想想矩阵乘法：\n",
    "\n",
    "$$\n",
    "\\mathbf{C} = \\mathbf{A}\\mathbf{B},\n",
    "$$\n",
    "\n",
    "或等价地\n",
    "\n",
    "$$ c_{i, j} = \\sum_{k} a_{i, k}b_{k, j}.$$\n",
    "\n",
    "这种模式是我们可以在张量上重复使用的。对于张量来说，没有一种通用的选择可以确定我们要对哪些索引求和，所以我们需要明确指定我们想要求和的具体索引。例如我们可以考虑\n",
    "\n",
    "$$\n",
    "y_{il} = \\sum_{jk} x_{ijkl}a_{jk}.\n",
    "$$\n",
    "\n",
    "这样的变换被称为*张量收缩*。它可以代表比单独的矩阵乘法更加灵活的一系列变换。\n",
    "\n",
    "作为一种常用的简化记法，我们可以注意到求和恰好是在表达式中出现超过一次的所有索引上进行的，因此人们经常使用*爱因斯坦记号*，其中隐含地对所有重复的索引求和。这给出了紧凑的表达式：\n",
    "\n",
    "$$\n",
    "y_{il} = x_{ijkl}a_{jk}.\n",
    "$$\n",
    "\n",
    "### 线性代数中常见的例子\n",
    "\n",
    "让我们看看之前见过的许多线性代数定义如何能用这种压缩的张量表示法表达：\n",
    "\n",
    "* $\\mathbf{v} \\cdot \\mathbf{w} = \\sum_i v_iw_i$\n",
    "* $\\|\\mathbf{v}\\|_2^{2} = \\sum_i v_iv_i$\n",
    "* $(\\mathbf{A}\\mathbf{v})_i = \\sum_j a_{ij}v_j$\n",
    "* $(\\mathbf{A}\\mathbf{B})_{ik} = \\sum_j a_{ij}b_{jk}$\n",
    "* $\\textrm{tr}(\\mathbf{A}) = \\sum_i a_{ii}$\n",
    "\n",
    "这样，我们可以用简短的张量表达式取代众多专门的记号。\n",
    "\n",
    "### 代码中的表达\n",
    "张量也可以在代码中灵活操作。如 :numref:`sec_linear-algebra` 所示，我们可以如下创建张量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60092e5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T19:30:28.472962Z",
     "iopub.status.busy": "2023-08-18T19:30:28.471989Z",
     "iopub.status.idle": "2023-08-18T19:30:28.482336Z",
     "shell.execute_reply": "2023-08-18T19:30:28.481119Z"
    },
    "origin_pos": 30,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 2]), torch.Size([2, 2, 3]), torch.Size([2]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define tensors\n",
    "B = torch.tensor([[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]])\n",
    "A = torch.tensor([[1, 2], [3, 4]])\n",
    "v = torch.tensor([1, 2])\n",
    "\n",
    "# Print out the shapes\n",
    "A.shape, B.shape, v.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdcbd57",
   "metadata": {
    "origin_pos": 32
   },
   "source": [
    "爱因斯坦求和已经被直接实现。\n",
    "在爱因斯坦求和中出现的指标可以作为一个字符串传递，\n",
    "后面跟着要操作的张量。\n",
    "例如，要实现矩阵乘法，\n",
    "我们可以考虑上面看到的爱因斯坦求和\n",
    "（$\\mathbf{A}\\mathbf{v} = a_{ij}v_j$）\n",
    "并去掉指标本身来得到实现："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b47b53c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T19:30:28.487310Z",
     "iopub.status.busy": "2023-08-18T19:30:28.486600Z",
     "iopub.status.idle": "2023-08-18T19:30:28.493572Z",
     "shell.execute_reply": "2023-08-18T19:30:28.492583Z"
    },
    "origin_pos": 34,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 5, 11]), tensor([ 5, 11]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reimplement matrix multiplication\n",
    "torch.einsum(\"ij, j -> i\", A, v), A@v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9cb807",
   "metadata": {
    "origin_pos": 36
   },
   "source": [
    "这是一个非常灵活的记法。\n",
    "例如，如果我们想计算\n",
    "传统上会写作\n",
    "\n",
    "$$\n",
    "c_{kl} = \\sum_{ij} \\mathbf{b}_{ijk}\\mathbf{a}_{il}v_j.\n",
    "$$\n",
    "\n",
    "可以通过爱因斯坦求和约定实现为："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba403495",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T19:30:28.498150Z",
     "iopub.status.busy": "2023-08-18T19:30:28.497621Z",
     "iopub.status.idle": "2023-08-18T19:30:28.507270Z",
     "shell.execute_reply": "2023-08-18T19:30:28.506042Z"
    },
    "origin_pos": 38,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 90, 126],\n",
       "        [102, 144],\n",
       "        [114, 162]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.einsum(\"ijk, il, j -> kl\", B, A, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcfabad",
   "metadata": {
    "origin_pos": 40
   },
   "source": [
    "这种记法对人类来说是可读且高效的，\n",
    "然而如果出于某种原因需要程序生成张量收缩时则显得冗长。\n",
    "因此，`einsum`提供了一种替代记法，\n",
    "通过为每个张量提供整数索引。\n",
    "例如，同样的张量收缩也可以写成："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa6b3ca6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T19:30:28.511952Z",
     "iopub.status.busy": "2023-08-18T19:30:28.511061Z",
     "iopub.status.idle": "2023-08-18T19:30:28.516610Z",
     "shell.execute_reply": "2023-08-18T19:30:28.515414Z"
    },
    "origin_pos": 42,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "# PyTorch does not support this type of notation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12c501b",
   "metadata": {
    "origin_pos": 44
   },
   "source": [
    "任一记号都允许在代码中简洁高效地表示张量收缩。\n",
    "\n",
    "## 总结\n",
    "* 向量可以被几何解释为点或空间中的方向。\n",
    "* 点积定义了任意高维空间中的角度概念。\n",
    "* 超平面是线和平面的高维推广。它们可用于定义决策平面，这通常用作分类任务的最后一步。\n",
    "* 矩阵乘法可以几何解释为对基础坐标的均匀变形。它们代表了一种非常受限但数学上干净的方法来变换向量。\n",
    "* 线性相关是一种方法，用于判断一组向量是否处于比预期更低维度的空间（比如说你有3个向量生活在2维空间中）。矩阵的秩是指其列中最大线性独立子集的大小。\n",
    "* 当矩阵的逆存在时，矩阵求逆允许我们找到另一个矩阵以取消第一个矩阵的作用。理论上矩阵求逆是有用的，但在实践中由于数值不稳定性需要小心处理。\n",
    "* 行列式允许我们测量一个矩阵如何扩张或收缩空间。非零行列式意味着可逆（非奇异）矩阵，而零值行列式意味着矩阵不可逆（奇异）。\n",
    "* 张量收缩和爱因斯坦求和提供了一种整洁且清晰的符号，用于表达机器学习中看到的许多计算。\n",
    "\n",
    "## 练习\n",
    "1. 之间的角度是多少\n",
    "$$\n",
    "\\vec v_1 = \\begin{bmatrix}\n",
    "1 \\\\ 0 \\\\ -1 \\\\ 2\n",
    "\\end{bmatrix}, \\qquad \\vec v_2 = \\begin{bmatrix}\n",
    "3 \\\\ 1 \\\\ 0 \\\\ 1\n",
    "\\end{bmatrix}?\n",
    "$$\n",
    "2. 判断题：$\\begin{bmatrix}1 & 2\\\\0&1\\end{bmatrix}$ 和 $\\begin{bmatrix}1 & -2\\\\0&1\\end{bmatrix}$ 是互逆的吗？\n",
    "3. 假设我们在平面上画了一个面积为 $100\\textrm{m}^2$ 的形状。通过矩阵\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "2 & 3\\\\\n",
    "1 & 2\n",
    "\\end{bmatrix}.\n",
    "$$\n",
    "变换后，这个图形的面积是多少？\n",
    "4. 下列哪组向量是线性独立的？\n",
    " * $\\left\\{\\begin{pmatrix}1\\\\0\\\\-1\\end{pmatrix}, \\begin{pmatrix}2\\\\1\\\\-1\\end{pmatrix}, \\begin{pmatrix}3\\\\1\\\\1\\end{pmatrix}\\right\\}$\n",
    " * $\\left\\{\\begin{pmatrix}3\\\\1\\\\1\\end{pmatrix}, \\begin{pmatrix}1\\\\1\\\\1\\end{pmatrix}, \\begin{pmatrix}0\\\\0\\\\0\\end{pmatrix}\\right\\}$\n",
    " * $\\left\\{\\begin{pmatrix}1\\\\1\\\\0\\end{pmatrix}, \\begin{pmatrix}0\\\\1\\\\-1\\end{pmatrix}, \\begin{pmatrix}1\\\\0\\\\1\\end{pmatrix}\\right\\}$\n",
    "5. 假设你有一个矩阵写作 $A = \\begin{bmatrix}c\\\\d\\end{bmatrix}\\cdot\\begin{bmatrix}a & b\\end{bmatrix}$ 对于某些选择的值 $a, b, c$ 和 $d$。判断题：这样的矩阵的行列式总是0吗？\n",
    "6. 向量 $e_1 = \\begin{bmatrix}1\\\\0\\end{bmatrix}$ 和 $e_2 = \\begin{bmatrix}0\\\\1\\end{bmatrix}$ 是正交的。对于矩阵 $A$ 来说，使得 $Ae_1$ 和 $Ae_2$ 正交的条件是什么？\n",
    "7. 如何使用爱因斯坦记号写出任意矩阵 $A$ 的 $\\textrm{tr}(\\mathbf{A}^4)$？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d98bab2",
   "metadata": {
    "origin_pos": 46,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "[讨论](https://discuss.d2l.ai/t/1084)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "required_libs": []
 },
 "nbformat": 4,
 "nbformat_minor": 5
}