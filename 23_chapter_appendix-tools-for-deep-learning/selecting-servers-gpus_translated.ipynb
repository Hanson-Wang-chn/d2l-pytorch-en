{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fd20f1c",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# 选择服务器和GPU\n",
    ":label:`sec_buy_gpu`\n",
    "\n",
    "深度学习训练通常需要大量的计算。目前，GPU是深度学习最具成本效益的硬件加速器。特别是与CPU相比，GPU更便宜且性能更高，通常高出一个数量级。此外，单个服务器可以支持多个GPU，高端服务器最多可支持8个。对于工程工作站来说，更典型的数字是最多4个GPU，因为超过这个数量后，散热、冷却和电源需求会迅速超出办公大楼的支持能力。对于更大的部署，云计算（例如，亚马逊的[P3](https://aws.amazon.com/ec2/instance-types/p3/)和[G4](https://aws.amazon.com/blogs/aws/in-the-works-ec2-instances-g4-with-nvidia-t4-gpus/)实例）是一个更为实际的解决方案。\n",
    "\n",
    "## 选择服务器\n",
    "\n",
    "通常不需要购买具有许多线程的高端CPU，因为大部分计算都在GPU上进行。不过，由于Python中的全局解释器锁（GIL），在拥有4-8个GPU的情况下，CPU的单线程性能仍然很重要。所有条件相同的情况下，这表明核心数较少但时钟频率较高的CPU可能是更经济的选择。例如，在6核4GHz和8核3.5GHz的CPU之间选择时，前者更优，尽管其总速度较低。\n",
    "一个重要考虑因素是GPU耗电大，因此散发大量热量。这需要非常好的冷却系统和足够大的机箱来使用GPU。如果可能，请遵循以下指南：\n",
    "\n",
    "1. **电源**。GPU耗电量很大。每台设备预算最高350W（请检查显卡的*峰值需求*而不是典型需求，因为高效的代码可能会消耗大量能量）。如果电源不足以满足需求，您会发现系统变得不稳定。\n",
    "1. **机箱大小**。GPU体积较大，辅助电源连接器通常需要额外空间。此外，较大的机箱更容易冷却。\n",
    "1. **GPU冷却**。如果您有大量的GPU，可能需要投资水冷系统。另外，目标是*参考设计*，即使它们的风扇较少，因为它们足够薄，可以在设备之间允许空气流通。如果您购买多风扇GPU，当安装多个GPU时可能会因为空间不足而无法获得足够的空气，从而导致热节流。\n",
    "1. **PCIe插槽**。将数据移入和移出GPU（以及在GPU之间交换数据）需要大量带宽。我们建议使用具有16条通道的PCIe 3.0插槽。如果您安装了多个GPU，请务必仔细阅读主板说明，以确保在同时使用多个GPU时仍能保持16$\\times$带宽，并且额外插槽为PCIe 3.0而非PCIe 2.0。有些主板在安装多个GPU时会降级到8$\\times$甚至4$\\times$带宽。部分原因是CPU提供的PCIe通道数量有限。\n",
    "\n",
    "简而言之，这里有一些构建深度学习服务器的建议：\n",
    "\n",
    "* **初学者**。购买低功耗的低端GPU（适合深度学习使用的廉价游戏GPU耗电150-200W）。如果您幸运的话，当前的计算机可能已经支持它。\n",
    "* **1个GPU**。4核的低端CPU就足够了，大多数主板也足够用。至少要32GB DRAM，并投资SSD用于本地数据访问。600W的电源应该足够。购买带有多个风扇的GPU。\n",
    "* **2个GPU**。4-6核的低端CPU就足够了。目标是64GB DRAM并投资SSD。两个高端GPU大约需要1000W。在主板方面，确保它们有两个PCIe 3.0 x16插槽。如果可以的话，选择在PCIe 3.0 x16插槽之间有60mm间距的主板，以便增加空气流通。在这种情况下，购买带有多个风扇的两块GPU。\n",
    "* **4个GPU**。确保您购买的CPU单线程速度相对较快（即高时钟频率）。您可能需要具有更多PCIe通道的CPU，例如AMD Threadripper。为了获得4个PCIe 3.0 x16插槽，您可能需要相对昂贵的主板，因为它们可能需要PLX来复用PCIe通道。购买窄型的参考设计GPU，让空气能在GPU之间流通。您需要1600-2000W的电源，办公室的插座可能不支持这么高的功率。这台服务器可能会运行得*非常响亮且发热严重*。不要把它放在桌子下面。建议128GB DRAM。获取SSD（1-2TB NVMe）用于本地存储，并使用RAID配置的一批硬盘来存储数据。\n",
    "* **8个GPU**。您需要购买专用的多GPU服务器机箱，配备多个冗余电源（例如，每个电源1600W的2+1配置）。这将需要双插槽服务器CPU，256GB ECC DRAM，高速网卡（推荐10 GBE），并且您需要检查服务器是否支持GPU的*物理尺寸*。消费者GPU和服务器GPU之间的气流和布线布局差异显著（例如RTX 2080 vs. Tesla V100）。这意味着由于电源线间隙不足或缺少合适的布线装置，您可能无法在服务器中安装消费级GPU（如一位合著者痛苦地发现的那样）。\n",
    "\n",
    "## 选择GPU\n",
    "\n",
    "目前，AMD和NVIDIA是专用GPU的主要制造商。NVIDIA率先进入深度学习领域，并通过CUDA提供对深度学习框架更好的支持。因此，大多数买家选择NVIDIA GPU。\n",
    "\n",
    "NVIDIA提供了两种类型的GPU，针对个人用户（例如通过GTX和RTX系列）和企业用户（通过Tesla系列）。这两种类型的GPU提供相当的计算能力。然而，企业用户的GPU通常使用（被动式）强制冷却、更多的内存和ECC（纠错）内存。这些GPU更适合数据中心，通常比消费级GPU贵十倍。\n",
    "\n",
    "如果您是一家拥有100多台服务器的大公司，应考虑NVIDIA Tesla系列，或者使用云中的GPU服务器。对于实验室或小型至中型企业，如果有10多台服务器，NVIDIA RTX系列可能是最经济的选择。您可以购买Supermicro或Asus机箱预配置的服务器，这些机箱可以高效地容纳4-8个GPU。\n",
    "\n",
    "GPU供应商通常每1-2年发布新一代产品，例如2017年发布的GTX 1000（Pascal）系列和2019年发布的RTX 2000（Turing）系列。每个系列都提供几种不同的型号，提供不同的性能水平。GPU性能主要由以下三个参数组合而成：\n",
    "\n",
    "1. **计算能力**。通常我们关注32位浮点计算能力。16位浮点训练（FP16）也开始成为主流。如果您只关心预测，也可以使用8位整数。最新一代的Turing GPU提供4位加速。不幸的是，撰写本文时，训练低精度网络的算法尚未广泛传播。\n",
    "1. **内存大小**。随着模型变大或训练过程中使用的批次增大，您将需要更多的GPU内存。检查HBM2（高带宽内存）与GDDR6（图形DDR）内存。HBM2更快但价格更高。\n",
    "1. **内存带宽**。只有当您的内存带宽充足时，才能充分发挥计算能力。如果使用GDDR6，请寻找宽内存总线。\n",
    "\n",
    "对于大多数用户来说，查看计算能力就足够了。请注意，许多GPU提供不同类型的加速。例如，NVIDIA的TensorCores可以将某些运算符的速度提高5$\\times$。确保您的库支持这一点。GPU内存不应少于4 GB（8 GB更好）。尽量避免使用GPU显示GUI（使用内置图形代替）。如果无法避免，请额外添加2 GB RAM以确保安全。\n",
    "\n",
    ":numref:`fig_flopsvsprice`比较了各种GTX 900、GTX 1000和RTX 2000系列型号的32位浮点计算能力和价格。建议的价格是在撰写本文时维基百科上的价格。\n",
    "\n",
    "![浮点计算能力和价格对比。 ](../img/flopsvsprice.svg)\n",
    ":label:`fig_flopsvsprice`\n",
    "\n",
    "\n",
    "我们可以看到几点：\n",
    "\n",
    "1. 在每个系列内，价格和性能大致成正比。Titan型号因其更大的GPU内存而享有显著溢价。然而，较新模型更具成本效益，可以通过比较980 Ti和1080 Ti看出。RTX 2000系列的价格似乎没有明显改善。但是，这是由于它们提供了远超的低精度性能（FP16、INT8和INT4）。\n",
    "2. GTX 1000系列的性价比约为900系列的两倍。\n",
    "3. 对于RTX 2000系列，性能（以GFLOPs计）是价格的*线性函数*。\n",
    "\n",
    "![浮点计算能力和能耗。 ](../img/wattvsprice.svg)\n",
    ":label:`fig_wattvsprice`\n",
    "\n",
    "\n",
    ":numref:`fig_wattvsprice`显示了能耗如何随计算量大致呈线性增长。其次，后来的几代更加节能。这似乎与RTX 2000系列的图表相矛盾。然而，这是由于TensorCores消耗了不成比例的能量所致。\n",
    "\n",
    "## 总结\n",
    "\n",
    "* 在构建服务器时要注意电源、PCIe总线通道、CPU单线程速度和冷却。\n",
    "* 如果可能的话，应购买最新的GPU代次。\n",
    "* 大规模部署应使用云计算。\n",
    "* 高密度服务器可能不兼容所有GPU。购买前请检查机械和冷却规格。\n",
    "* 使用FP16或更低精度以实现高效率。\n",
    "\n",
    "[讨论](https://discuss.d2l.ai/t/425)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "required_libs": []
 },
 "nbformat": 4,
 "nbformat_minor": 5
}