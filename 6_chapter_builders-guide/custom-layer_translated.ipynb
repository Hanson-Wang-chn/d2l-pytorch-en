{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e5f706d",
   "metadata": {
    "origin_pos": 1
   },
   "source": [
    "# 自定义层\n",
    "\n",
    "深度学习成功的一个因素\n",
    "是提供了各种各样的层\n",
    "这些层可以以创造性的方式组合\n",
    "设计出适合各种任务的架构。\n",
    "例如，研究人员发明了专门处理图像、文本、\n",
    "循环遍历序列数据\n",
    "以及\n",
    "执行动态规划的层。\n",
    "迟早你会需要\n",
    "一个在深度学习框架中尚不存在的层。\n",
    "在这种情况下，你必须构建一个自定义层。\n",
    "在本节中，我们将向你展示如何操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b2079e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T19:31:10.693752Z",
     "iopub.status.busy": "2023-08-18T19:31:10.693415Z",
     "iopub.status.idle": "2023-08-18T19:31:13.986742Z",
     "shell.execute_reply": "2023-08-18T19:31:13.985398Z"
    },
    "origin_pos": 3,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6181d4",
   "metadata": {
    "origin_pos": 6
   },
   "source": [
    "## (**没有参数的层**)\n",
    "\n",
    "首先，我们构建一个自定义层，\n",
    "这个层本身没有任何参数。\n",
    "如果你还记得我们在:numref:`sec_model_construction`中\n",
    "对模块的介绍，这应该看起来很熟悉。\n",
    "下面的`CenteredLayer`类只是\n",
    "从其输入中减去均值。\n",
    "要构建它，我们只需要继承\n",
    "基础层类并实现前向传播函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21e03034",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T19:31:13.993899Z",
     "iopub.status.busy": "2023-08-18T19:31:13.993311Z",
     "iopub.status.idle": "2023-08-18T19:31:14.001595Z",
     "shell.execute_reply": "2023-08-18T19:31:14.000547Z"
    },
    "origin_pos": 8,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "class CenteredLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, X):\n",
    "        return X - X.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b36f65b",
   "metadata": {
    "origin_pos": 11
   },
   "source": [
    "让我们通过向其中输入一些数据来验证我们的层是否按预期工作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34c473c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T19:31:14.006461Z",
     "iopub.status.busy": "2023-08-18T19:31:14.005870Z",
     "iopub.status.idle": "2023-08-18T19:31:14.035296Z",
     "shell.execute_reply": "2023-08-18T19:31:14.034301Z"
    },
    "origin_pos": 12,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2., -1.,  0.,  1.,  2.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = CenteredLayer()\n",
    "layer(torch.tensor([1.0, 2, 3, 4, 5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c4de56",
   "metadata": {
    "origin_pos": 13
   },
   "source": [
    "我们现在可以[**将我们的层作为组件\n",
    "用于构建更复杂的模型。**]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da630405",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T19:31:14.040444Z",
     "iopub.status.busy": "2023-08-18T19:31:14.040108Z",
     "iopub.status.idle": "2023-08-18T19:31:14.044820Z",
     "shell.execute_reply": "2023-08-18T19:31:14.043922Z"
    },
    "origin_pos": 15,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "net = nn.Sequential(nn.LazyLinear(128), CenteredLayer())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a31b206",
   "metadata": {
    "origin_pos": 18
   },
   "source": [
    "作为一种额外的检查，我们可以发送随机数据\n",
    "通过网络并检查其平均值是否确实为0。\n",
    "因为我们处理的是浮点数，\n",
    "我们可能仍会看到一个非常小的非零数字\n",
    "这是由于量化造成的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "370e0abb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T19:31:14.048310Z",
     "iopub.status.busy": "2023-08-18T19:31:14.047972Z",
     "iopub.status.idle": "2023-08-18T19:31:14.059041Z",
     "shell.execute_reply": "2023-08-18T19:31:14.057938Z"
    },
    "origin_pos": 20,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-6.5193e-09, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = net(torch.rand(4, 8))\n",
    "Y.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ea9d42",
   "metadata": {
    "origin_pos": 23
   },
   "source": [
    "## [**带有参数的层**]\n",
    "\n",
    "现在我们已经知道如何定义简单的层，\n",
    "接下来让我们学习如何定义可以通过训练调整参数的层。\n",
    "我们可以使用内置函数来创建参数，这些函数\n",
    "提供了一些基本的管理功能。\n",
    "特别是，它们控制访问、初始化、\n",
    "共享、保存和加载模型参数。\n",
    "这样，除了其他好处之外，我们不需要为每个自定义层\n",
    "编写自定义的序列化例程。\n",
    "\n",
    "现在让我们实现我们自己的全连接层版本。\n",
    "回想一下，这一层需要两个参数，\n",
    "一个表示权重，另一个表示偏置。\n",
    "在这个实现中，我们默认集成了ReLU激活函数。\n",
    "该层需要两个输入参数：`in_units` 和 `units`，分别\n",
    "表示输入和输出的数量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d07e84dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T19:31:14.063246Z",
     "iopub.status.busy": "2023-08-18T19:31:14.062888Z",
     "iopub.status.idle": "2023-08-18T19:31:14.069269Z",
     "shell.execute_reply": "2023-08-18T19:31:14.068283Z"
    },
    "origin_pos": 25,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "class MyLinear(nn.Module):\n",
    "    def __init__(self, in_units, units):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(in_units, units))\n",
    "        self.bias = nn.Parameter(torch.randn(units,))\n",
    "\n",
    "    def forward(self, X):\n",
    "        linear = torch.matmul(X, self.weight.data) + self.bias.data\n",
    "        return F.relu(linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218be348",
   "metadata": {
    "origin_pos": 29,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "接下来，我们实例化 `MyLinear` 类并访问其模型参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a664799",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T19:31:14.074206Z",
     "iopub.status.busy": "2023-08-18T19:31:14.073211Z",
     "iopub.status.idle": "2023-08-18T19:31:14.080883Z",
     "shell.execute_reply": "2023-08-18T19:31:14.079861Z"
    },
    "origin_pos": 31,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.4783,  0.4284, -0.0899],\n",
       "        [-0.6347,  0.2913, -0.0822],\n",
       "        [-0.4325, -0.1645, -0.3274],\n",
       "        [ 1.1898,  0.6482, -1.2384],\n",
       "        [-0.1479,  0.0264, -0.9597]], requires_grad=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = MyLinear(5, 3)\n",
    "linear.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b12b77",
   "metadata": {
    "origin_pos": 34
   },
   "source": [
    "我们可以直接使用自定义层进行前向传播计算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "859b12e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T19:31:14.084676Z",
     "iopub.status.busy": "2023-08-18T19:31:14.084328Z",
     "iopub.status.idle": "2023-08-18T19:31:14.091968Z",
     "shell.execute_reply": "2023-08-18T19:31:14.090864Z"
    },
    "origin_pos": 36,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.9316, 0.0000],\n",
       "        [0.1808, 1.4208, 0.0000]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear(torch.rand(2, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6811c960",
   "metadata": {
    "origin_pos": 39
   },
   "source": [
    "我们也可以（**使用自定义层构建模型。**）\n",
    "一旦我们有了它，就可以像使用内置的全连接层一样使用它。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53f3a28a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T19:31:14.096505Z",
     "iopub.status.busy": "2023-08-18T19:31:14.095515Z",
     "iopub.status.idle": "2023-08-18T19:31:14.104253Z",
     "shell.execute_reply": "2023-08-18T19:31:14.102782Z"
    },
    "origin_pos": 41,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000],\n",
       "        [13.0800]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential(MyLinear(64, 8), MyLinear(8, 1))\n",
    "net(torch.rand(2, 64))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2a529d",
   "metadata": {
    "origin_pos": 44
   },
   "source": [
    "## 摘要\n",
    "\n",
    "我们可以通过基本的层类来设计自定义层。这使我们能够定义与库中任何现有层行为不同的灵活新层。\n",
    "一旦定义，自定义层可以在任意上下文和架构中被调用。\n",
    "层可以有局部参数，这些参数可以通过内置函数创建。\n",
    "\n",
    "## 练习\n",
    "\n",
    "1. 设计一个层，该层接收输入并计算张量缩减，即返回 $y_k = \\sum_{i, j} W_{ijk} x_i x_j$。\n",
    "1. 设计一个层，该层返回数据的前半部分傅里叶系数。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7288fd89",
   "metadata": {
    "origin_pos": 46,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "[讨论](https://discuss.d2l.ai/t/59)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "required_libs": []
 },
 "nbformat": 4,
 "nbformat_minor": 5
}