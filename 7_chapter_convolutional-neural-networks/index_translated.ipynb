{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5951640a",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# 卷积神经网络\n",
    ":label:`chap_cnn`\n",
    "\n",
    "图像数据表示为像素的二维网格，无论是单色还是彩色。因此，每个像素对应一个或多个数值。到目前为止，我们忽略了这种丰富的结构，通过将图像“展平”成向量来处理，而不考虑像素之间的空间关系。为了将生成的一维向量输入全连接的多层感知机中，这种令人深感不满的方法是必要的。\n",
    "\n",
    "由于这些网络对特征的顺序不变，无论我们是否保留与像素的空间结构相对应的顺序，或者在拟合多层感知机的参数之前重新排列设计矩阵的列，我们都可能得到类似的结果。理想情况下，我们应该利用先验知识，即附近的像素通常彼此相关，来构建有效的模型以从图像数据中学习。\n",
    "\n",
    "本章介绍了*卷积神经网络*（CNNs）:cite:`LeCun.Jackel.Bottou.ea.1995`，这是一种专为此目的设计的强大神经网络家族。基于CNN的架构现在在计算机视觉领域无处不在。例如，在ImageNet集合上:cite:`Deng.Dong.Socher.ea.2009`，只有使用卷积神经网络，简称ConvNets，才提供了显著的性能改进:cite:`Krizhevsky.Sutskever.Hinton.2012`。\n",
    "\n",
    "现代CNN，如人们俗称的那样，其设计灵感来自于生物学、群论以及大量的实验调整。除了在实现准确模型时的样本效率外，CNN往往在计算上也很高效，一方面是因为它们比全连接架构需要更少的参数，另一方面是因为卷积易于在GPU核心上并行化:cite:`Chetlur.Woolley.Vandermersch.ea.2014`。因此，实践者尽可能地应用CNN，并且它们甚至在具有单维序列结构的任务上也逐渐成为可靠的竞争对手，比如音频:cite:`Abdel-Hamid.Mohamed.Jiang.ea.2014`、文本:cite:`Kalchbrenner.Grefenstette.Blunsom.2014`和时间序列分析:cite:`LeCun.Bengio.ea.1995`，这些任务传统上使用循环神经网络。一些巧妙适应的CNN也被用于图结构数据:cite:`Kipf.Welling.2016`和推荐系统中。\n",
    "\n",
    "首先，我们将更深入地探讨卷积神经网络的动机。接下来，我们将介绍构成所有卷积网络基础的基本操作。这包括卷积层本身、细节如填充和步幅、用于汇总相邻空间区域信息的池化层、每层使用的多个通道，以及对现代架构结构的仔细讨论。本章将以LeNet为例结束，这是第一个成功部署的卷积网络，远早于现代深度学习的兴起。在下一章中，我们将深入研究一些流行且相对较新的CNN架构的完整实现，这些设计代表了现代实践者常用的大多数技术。\n",
    "\n",
    ":begin_tab:toc\n",
    " - [why-conv](why-conv.ipynb)\n",
    " - [conv-layer](conv-layer.ipynb)\n",
    " - [padding-and-strides](padding-and-strides.ipynb)\n",
    " - [channels](channels.ipynb)\n",
    " - [pooling](pooling.ipynb)\n",
    " - [lenet](lenet.ipynb)\n",
    ":end_tab:"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "required_libs": []
 },
 "nbformat": 4,
 "nbformat_minor": 5
}