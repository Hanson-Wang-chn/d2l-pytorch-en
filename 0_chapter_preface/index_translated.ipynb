{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc7fc286",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# 序言\n",
    "\n",
    "就在几年前，还没有大量的深度学习科学家在大公司和初创企业中开发智能产品和服务。当我们进入这个领域时，机器学习还没有成为日报的头条新闻。我们的父母根本不知道什么是机器学习，更不用说为什么我们会选择它而不是医学或法律职业了。机器学习是一个前景广阔的学术学科，其工业意义仅限于包括语音识别和计算机视觉在内的一小部分实际应用。此外，这些应用中的许多都需要如此多的专业知识，以至于它们经常被视为完全独立的领域，其中机器学习只是一个小组成部分。当时，神经网络——本书重点讨论的深度学习方法的前身——通常被认为已经过时。\n",
    "\n",
    "然而仅仅几年时间，深度学习就出人意料地席卷了世界，在计算机视觉、自然语言处理、自动语音识别、强化学习和生物医学信息学等众多领域推动了快速进步。此外，深度学习在这么多实用任务上的成功甚至催化了理论机器学习和统计学的发展。有了这些进展，我们现在可以建造比以往任何时候都更加自主驾驶的汽车（尽管不如某些公司可能让你相信的那样自主），通过提出澄清问题来调试代码的对话系统，以及在围棋等棋盘游戏中击败世界上最好的人类玩家的软件代理，这曾经被认为还需要几十年才能实现。这些工具已经在行业和社会中发挥着越来越广泛的影响，改变了电影制作方式、疾病诊断方式，并在基础科学——从天体物理学到气候建模，再到天气预测和生物医学——中扮演着日益重要的角色。\n",
    "\n",
    "## 关于这本书\n",
    "\n",
    "这本书代表了我们试图让深度学习变得易于接近的努力，教你*概念*、*背景*和*代码*。\n",
    "\n",
    "### 结合代码、数学和HTML的一种媒介\n",
    "\n",
    "对于任何计算技术要达到其全部影响，必须被很好地理解、很好地记录，并由成熟且维护良好的工具支持。关键思想应该被清晰地提炼出来，尽量减少将新从业者带入最新状态所需的时间。成熟的库应该自动化常见任务，而示例代码应该使从业者能够轻松修改、应用和扩展常见的应用程序以满足他们的需求。\n",
    "\n",
    "例如，动态Web应用程序。尽管像亚马逊这样的公司在20世纪90年代就已经开发出了成功的数据库驱动Web应用程序，但这项技术对创意企业家的帮助潜力直到过去十年才得到更大程度的实现，部分原因是强大且文档齐全的框架的发展。\n",
    "\n",
    "测试深度学习的潜力提出了独特的挑战，因为任何单一的应用程序都会结合各种学科。应用深度学习需要同时理解：(i) 以特定方式构建问题的动机；(ii) 给定模型的数学形式；(iii) 将模型拟合到数据的优化算法；(iv) 告诉我们何时应期望模型泛化到未见数据的统计原理，以及证实它们确实已经泛化的实际方法；以及 (v) 高效训练模型所需的工程技巧，避免数值计算中的陷阱并充分利用可用硬件。在一个地方教授批判性思维技能来制定问题、解决这些问题的数学方法以及实施这些解决方案的软件工具，这是一个艰巨的挑战。我们在这本书中的目标是提供一个统一的资源，帮助潜在的从业者迅速上手。\n",
    "\n",
    "当我们开始这个书籍项目时，没有资源能够同时做到：(i) 保持更新；(ii) 以足够的技术深度覆盖现代机器学习实践的广度；以及 (iii) 将教科书质量的阐述与教程预期的干净可运行代码交织在一起。我们找到了很多代码示例，说明如何使用给定的深度学习框架（例如，如何在TensorFlow中进行基本的数值计算）或实现特定技术（例如，LeNet、AlexNet、ResNet等的代码片段），分散在各种博客文章和GitHub仓库中。然而，这些示例通常只关注*如何*实现给定的方法，但忽略了关于*为何*做出某些算法决策的讨论。虽然一些互动资源偶尔出现来解决特定主题，例如发布在[Distill](http://distill.pub)网站上的引人入胜的博客文章或个人博客，但它们只涵盖了深度学习中的选定主题，而且通常缺乏相关代码。另一方面，虽然几本深度学习教科书已经出现——例如 :citet:`Goodfellow.Bengio.Courville.2016`，它提供了对深度学习基础知识的全面调查——但这些资源并未将描述与代码实现结合起来，有时会让读者对如何实现这些概念感到困惑。此外，太多资源隐藏在商业课程提供商的付费墙后。\n",
    "\n",
    "我们着手创建一种资源，它可以：(i) 对每个人免费提供；(ii) 提供足够的技术深度，为实际上成为一名应用机器学习科学家提供起点；(iii) 包含可运行的代码，向读者展示*如何*在实践中解决问题；(iv) 允许快速更新，既由我们自己也由广大社区；以及 (v) 有一个[论坛](https://discuss.d2l.ai/c/5)，用于讨论技术细节和回答问题。\n",
    "\n",
    "这些目标往往相互冲突。公式、定理和引用最好用LaTeX管理和布局。代码最好用Python描述。网页原生使用HTML和JavaScript。此外，我们希望内容既能作为可执行代码访问，也能作为实体书、可下载的PDF和互联网上的网站访问。没有任何工作流程似乎适合这些需求，因此我们决定组装自己的(:numref:`sec_how_to_contribute`)。我们选择了GitHub来共享源代码并促进社区贡献；Jupyter笔记本用于混合代码、方程和文本；Sphinx作为渲染引擎；以及Discourse作为讨论平台。虽然我们的系统并不完美，但这些选择在竞争的关注点之间达成了妥协。我们相信，《深入深度学习》可能是第一本使用这种集成工作流出版的书籍。\n",
    "\n",
    "### 边做边学\n",
    "\n",
    "许多教科书按顺序呈现概念，每个概念都详尽无遗。例如，:citet:`Bishop.2006`的优秀教科书，每章都讲得非常透彻，以至于到达线性回归章节需要付出不少努力。专家们正是因为它的详尽而喜欢这本书，但对于真正的初学者来说，这一特性限制了它作为入门读物的实用性。\n",
    "\n",
    "在这本书中，我们*及时*教授大多数概念。换句话说，你将在需要完成某个实际目的的确切时刻学习这些概念。虽然我们在一开始花了一些时间来教授线性代数和概率等基本预备知识，但我们希望你在担心更神秘的概念之前，先体验训练第一个模型带来的满足感。\n",
    "\n",
    "除了少数几个提供基本数学背景速成课程的初步笔记本外，每一后续章节既介绍合理数量的新概念，又提供使用真实数据集的多个自包含的工作示例。这提出了一个组织上的挑战。有些模型从逻辑上讲可以在一个笔记本中分组。有些想法可能通过连续执行几个模型来最好地教授。相比之下，坚持*一个工作示例，一个笔记本*的政策有一个很大的优势：这使得你尽可能容易地通过利用我们的代码开始自己的研究项目。只需复制一个笔记本并开始修改即可。\n",
    "\n",
    "在整个过程中，我们将可运行的代码与必要的背景材料交织在一起。一般来说，我们在解释完全之前偏向于先提供工具（通常稍后会补充背景）。例如，我们可能会在解释为什么它有用或提供它为什么有效的直觉之前使用*随机梯度下降*。这有助于为从业者提供快速解决问题所需的弹药，代价是要求读者信任我们的一些策展决定。\n",
    "\n",
    "这本书从零开始教授深度学习概念。有时，我们会深入探讨模型的细节，这些细节通常会被现代深度学习框架的用户所隐藏。这种情况尤其出现在基础教程中，我们希望你了解给定层或优化器发生的一切。在这种情况下，我们通常会呈现两个版本的示例：一个是完全从头开始实现的，只依赖类似NumPy的功能和自动微分；另一个更实用的示例，使用深度学习框架的高级API编写简洁的代码。在解释了某个组件的工作原理之后，我们在随后的教程中依赖高级API。\n",
    "\n",
    "### 内容与结构\n",
    "\n",
    "本书大致可分为三个部分，涉及预备知识、深度学习技术和专注于真实系统和应用的高级主题(:numref:`fig_book_org`)。\n",
    "\n",
    "![书籍结构。](../img/book-org.svg)\n",
    ":label:`fig_book_org`\n",
    "\n",
    "* **第1部分：基础和预备知识**。:numref:`chap_introduction` 是深度学习的介绍。然后，在:numref:`chap_preliminaries` 中，我们快速带你掌握动手深度学习所需的先决条件，如如何存储和操作数据，以及如何基于线性代数、微积分和概率的基本概念应用各种数值运算。:numref:`chap_regression` 和 :numref:`chap_perceptrons` 涵盖了深度学习中最基本的概念和技术，包括回归和分类；线性模型；多层感知机；以及过拟合和正则化。\n",
    "\n",
    "* **第2部分：现代深度学习技术**。:numref:`chap_computation` 描述了深度学习系统的计算关键组件，并为我们随后实现更复杂的模型奠定了基础。接下来，:numref:`chap_cnn` 和 :numref:`chap_modern_cnn` 介绍了卷积神经网络 (CNNs)，这是构成大多数现代计算机视觉系统骨干的强大工具。同样，:numref:`chap_rnn` 和 :numref:`chap_modern_rnn` 介绍了循环神经网络 (RNNs)，这些模型利用数据中的序列（例如，时间）结构，常用于自然语言处理和时间序列预测。在 :numref:`chap_attention-and-transformers` 中，我们描述了一类相对较新的基于所谓*注意力机制*的模型，这类模型已经取代RNNs成为大多数自然语言处理任务的主要架构。这些部分将使你跟上广泛使用的最强大和通用的工具的步伐。\n",
    "\n",
    "* **第3部分：可扩展性、效率和应用**（在线[获取](https://d2l.ai)）。在第12章中，我们讨论了几种常用的优化算法，用于训练深度学习模型。接着，在第13章中，我们检查了影响深度学习代码计算性能的几个关键因素。然后，在第14章中，我们展示了深度学习在计算机视觉中的主要应用。最后，在第15章和第16章中，我们演示了如何预训练语言表示模型，并将其应用于自然语言处理任务。\n",
    "\n",
    "### 代码\n",
    ":label:`sec_code`\n",
    "\n",
    "本书的大部分章节都有可执行代码。我们认为，某些直觉最好通过试验和错误来发展，即小幅调整代码并观察结果。理想情况下，优雅的数学理论可以准确告诉我们如何调整代码以达到预期的结果。然而，当今的深度学习从业者常常必须在没有坚实理论指导的情况下前行。尽管我们尽力尝试，但目前仍缺乏各种技术有效性的正式解释，原因多种多样：表征这些模型的数学可能非常困难；解释可能取决于当前尚无明确定义的数据属性；并且对这些话题的认真研究最近才刚刚起步。我们希望随着深度学习理论的进步，本书的每一版都将提供超越当前水平的见解。\n",
    "\n",
    "为了避免不必要的重复，我们在`d2l`包中捕获了一些最常用和最频繁导入的函数和类。整个过程中，我们用`#@save`标记代码块（如函数、类或导入语句集合），以表明它们将通过`d2l`包在后面访问。我们在:numref:`sec_d2l`中详细概述了这些类和函数。`d2l`包是轻量级的，只需要以下依赖项："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ec1addc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T19:26:13.372553Z",
     "iopub.status.busy": "2023-08-18T19:26:13.371850Z",
     "iopub.status.idle": "2023-08-18T19:26:14.298913Z",
     "shell.execute_reply": "2023-08-18T19:26:14.297835Z"
    },
    "origin_pos": 1,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "#@save\n",
    "import collections\n",
    "import hashlib\n",
    "import inspect\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import shutil\n",
    "import sys\n",
    "import tarfile\n",
    "import time\n",
    "import zipfile\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import requests\n",
    "from IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib_inline import backend_inline\n",
    "\n",
    "d2l = sys.modules[__name__]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43382b4a",
   "metadata": {
    "origin_pos": 3,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "本书中的大部分代码基于PyTorch，\n",
    "这是一个深受深度学习研究社区热烈欢迎的开源框架。\n",
    "本书中的所有代码都在最新稳定版的PyTorch下通过了测试。\n",
    "然而，由于深度学习的快速发展，\n",
    "印刷版中的一些代码可能在未来版本的PyTorch中无法正常工作。\n",
    "我们计划保持在线版本的更新。\n",
    "如果您遇到任何问题，请参阅:ref:`chap_installation`\n",
    "以更新您的代码和运行环境。\n",
    "下面列出了我们在PyTorch实现中的依赖项。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a9cc53a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T19:26:14.303163Z",
     "iopub.status.busy": "2023-08-18T19:26:14.302440Z",
     "iopub.status.idle": "2023-08-18T19:26:16.150398Z",
     "shell.execute_reply": "2023-08-18T19:26:16.148962Z"
    },
    "origin_pos": 7,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "#@save\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "from scipy.spatial import distance_matrix\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9381f00a",
   "metadata": {
    "origin_pos": 10
   },
   "source": [
    "### 目标读者\n",
    "\n",
    "这本书适合寻求掌握深度学习实用技术的学生（本科生或研究生）、工程师和研究人员。因为我们从零开始解释每一个概念，所以不需要有深度学习或机器学习的背景知识。全面解释深度学习的方法需要一些数学和编程知识，但我们只假设你具备一些基础知识，包括适量的线性代数、微积分、概率论和Python编程。如果你忘记了某些内容，[在线附录](https://d2l.ai/chapter_appendix-mathematics-for-deep-learning/index.html)提供了本书中大部分数学知识的复习。通常情况下，我们会优先考虑直觉和想法，而不是数学严谨性。如果你想扩展这些基础，以理解我们的书，我们很高兴推荐一些其他优秀的资源：*Linear Analysis* by :citet:`Bollobas.1999` 深入介绍了线性代数和泛函分析。*All of Statistics* :cite:`Wasserman.2013` 提供了统计学的精彩介绍。Joe Blitzstein的[书籍](https://www.amazon.com/Introduction-Probability-Chapman-Statistical-Science/dp/1138369918) 和[课程](https://projects.iq.harvard.edu/stat110/home) 是概率和推理教学中的瑰宝。如果你以前没有使用过Python，你可能想浏览这个 [Python教程](http://learnpython.org/)。\n",
    "\n",
    "### 笔记本、网站、GitHub和论坛\n",
    "\n",
    "我们所有的笔记本都可以在[D2L.ai网站](https://d2l.ai)和[GitHub](https://github.com/d2l-ai/d2l-en)上下载。与本书相关，我们还推出了一个讨论论坛，位于[discuss.d2l.ai](https://discuss.d2l.ai/c/5)。每当你对书中任何部分有疑问时，都可以在每个笔记本末尾找到相关讨论页面的链接。\n",
    "\n",
    "## 致谢\n",
    "\n",
    "我们要感谢数百名为英文版和中文版草稿做出贡献的人。他们帮助改进了内容并提供了宝贵的反馈。这本书最初是用MXNet作为主要框架实现的。我们感谢Anirudh Dagar和Yuan Tang分别将大部分早期MXNet代码改编为PyTorch和TensorFlow实现。自2021年7月以来，我们重新设计并在PyTorch、MXNet和TensorFlow中重新实现了这本书，选择PyTorch作为主要框架。我们感谢Anirudh Dagar将大部分最近的PyTorch代码改编为JAX实现。我们感谢来自百度的高胜武、胡六军、张戈和谢杰航将大部分最近的PyTorch代码改编为PaddlePaddle实现。我们感谢张帅将出版社的LaTeX样式整合到PDF构建中。\n",
    "\n",
    "在GitHub上，我们要感谢每一位使这本英文草稿变得更好的贡献者。他们的GitHub ID或名字（无特定顺序）如下：alxnorden, avinashingit, bowen0701, brettkoonce, Chaitanya Prakash Bapat, cryptonaut, Davide Fiocco, edgarroman, gkutiel, John Mitro, Liang Pu, Rahul Agarwal, Mohamed Ali Jamaoui, Michael (Stu) Stewart, Mike Müller, NRauschmayr, Prakhar Srivastav, sad-, sfermigier, Sheng Zha, sundeepteki, topecongiro, tpdi, vermicelli, Vishaal Kapoor, Vishwesh Ravi Shrimali, YaYaB, Yuhong Chen, Evgeniy Smirnov, lgov, Simon Corston-Oliver, Igor Dzreyev, Ha Nguyen, pmuens, Andrei Lukovenko, senorcinco, vfdev-5, dsweet, Mohammad Mahdi Rahimi, Abhishek Gupta, uwsd, DomKM, Lisa Oakley, Bowen Li, Aarush Ahuja, Prasanth Buddareddygari, brianhendee, mani2106, mtn, lkevinzc, caojilin, Lakshya, Fiete Lüer, Surbhi Vijayvargeeya, Muhyun Kim, dennismalmgren, adursun, Anirudh Dagar, liqingnz, Pedro Larroy, lgov, ati-ozgur, Jun Wu, Matthias Blume, Lin Yuan, geogunow, Josh Gardner, Maximilian Böther, Rakib Islam, Leonard Lausen, Abhinav Upadhyay, rongruosong, Steve Sedlmeyer, Ruslan Baratov, Rafael Schlatter, liusy182, Giannis Pappas, ati-ozgur, qbaza, dchoi77, Adam Gerson, Phuc Le, Mark Atwood, christabella, vn09, Haibin Lin, jjangga0214, RichyChen, noelo, hansent, Giel Dops, dvincent1337, WhiteD3vil, Peter Kulits, codypenta, joseppinilla, ahmaurya, karolszk, heytitle, Peter Goetz, rigtorp, Tiep Vu, sfilip, mlxd, Kale-ab Tessera, Sanjar Adilov, MatteoFerrara, hsneto, Katarzyna Biesialska, Gregory Bruss, Duy–Thanh Doan, paulaurel, graytowne, Duc Pham, sl7423, Jaedong Hwang, Yida Wang, cys4, clhm, Jean Kaddour, austinmw, trebeljahr, tbaums, Cuong V. Nguyen, pavelkomarov, vzlamal, NotAnotherSystem, J-Arun-Mani, jancio, eldarkurtic, the-great-shazbot, doctorcolossus, gducharme, cclauss, Daniel-Mietchen, hoonose, biagiom, abhinavsp0730, jonathanhrandall, ysraell, Nodar Okroshiashvili, UgurKap, Jiyang Kang, StevenJokes, Tomer Kaftan, liweiwp, netyster, ypandya, NishantTharani, heiligerl, SportsTHU, Hoa Nguyen, manuel-arno-korfmann-webentwicklung, aterzis-personal, nxby, Xiaoting He, Josiah Yoder, mathresearch, mzz2017, jroberayalas, iluu, ghejc, BSharmi, vkramdev, simonwardjones, LakshKD, TalNeoran, djliden, Nikhil95, Oren Barkan, guoweis, haozhu233, pratikhack, Yue Ying, tayfununal, steinsag, charleybeller, Andrew Lumsdaine, Jiekui Zhang, Deepak Pathak, Florian Donhauser, Tim Gates, Adriaan Tijsseling, Ron Medina, Gaurav Saha, Murat Semerci, Lei Mao, Levi McClenny, Joshua Broyde, jake221, jonbally, zyhazwraith, Brian Pulfer, Nick Tomasino, Lefan Zhang, Hongshen Yang, Vinney Cavallo, yuntai, Yuanxiang Zhu, amarazov, pasricha, Ben Greenawald, Shivam Upadhyay, Quanshangze Du, Biswajit Sahoo, Parthe Pandit, Ishan Kumar, HomunculusK, Lane Schwartz, varadgunjal, Jason Wiener, Armin Gholampoor, Shreshtha13, eigen-arnav, Hyeonggyu Kim, EmilyOng, Bálint Mucsányi, Chase DuBois, Juntian Tao, Wenxiang Xu, Lifu Huang, filevich, quake2005, nils-werner, Yiming Li, Marsel Khisamutdinov, Francesco \"Fuma\" Fumagalli, Peilin Sun, Vincent Gurgul, qingfengtommy, Janmey Shukla, Mo Shan, Kaan Sancak, regob, AlexSauer, Gopalakrishna Ramachandra, Tobias Uelwer, Chao Wang, Tian Cao, Nicolas Corthorn, akash5474, kxxt, zxydi1992, Jacob Britton, Shuangchi He, zhmou, krahets, Jie-Han Chen, Atishay Garg, Marcel Flygare, adtygan, Nik Vaessen, bolded, Louis Schlessinger, Balaji Varatharajan, atgctg, Kaixin Li, Victor Barbaros, Riccardo Musto, Elizabeth Ho, azimjonn, Guilherme Miotto, Alessandro Finamore, Joji Joseph, Anthony Biel, Zeming Zhao, shjustinbaek, gab-chen, nantekoto, Yutaro Nishiyama, Oren Amsalem, Tian-MaoMao, Amin Allahyar, Gijs van Tulder, Mikhail Berkov, iamorphen, Matthew Caseres, Andrew Walsh, pggPL, RohanKarthikeyan, Ryan Choi, and Likun Lei。\n",
    "\n",
    "我们感谢Amazon Web Services，特别是Wen-Ming Ye, George Karypis, Swami Sivasubramanian, Peter DeSantis, Adam Selipsky, 和Andrew Jassy对我们撰写这本书的慷慨支持。如果没有可用的时间、资源、同事间的讨论以及持续的鼓励，这本书是不可能完成的。在准备出版过程中，剑桥大学出版社提供了极好的支持。我们感谢我们的责任编辑David Tranah的帮助和专业精神。\n",
    "\n",
    "## 摘要\n",
    "\n",
    "深度学习已经彻底改变了模式识别，引入了现在驱动广泛技术的技术，如计算机视觉、自然语言处理和自动语音识别。要成功应用深度学习，你必须了解如何定义问题、建模的基本数学、将模型拟合到数据的算法以及实施这一切的工程技巧。这本书提供了一个全面的资源，包括文字、图表、数学和代码，全部集中在一个地方。\n",
    "\n",
    "## 练习\n",
    "\n",
    "1. 在本书的讨论论坛[discuss.d2l.ai](https://discuss.d2l.ai/)上注册一个账户。\n",
    "1. 在你的电脑上安装Python。\n",
    "1. 通过章节底部的链接访问论坛，在那里你可以寻求帮助、讨论这本书，并通过与作者和更广泛的社区互动来找到问题的答案。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe50a56",
   "metadata": {
    "origin_pos": 12,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "[讨论](https://discuss.d2l.ai/t/20)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "required_libs": []
 },
 "nbformat": 4,
 "nbformat_minor": 5
}